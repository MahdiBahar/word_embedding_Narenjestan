{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea5a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240087ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی وارد شده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\"\n",
    "# text = \"در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده \"\n",
    "# text2 = \" درخواست خدمت اعتباری تغییر ضامن پیغام خطای مصوبه فوق فاقد وثیقه ضامن پذیر است دریافت می‌گردد چاپ مجدد پیشنهاد بررسی گردد در صورتی که تیک قرارداد لازم اجرا ثبت شده باشد می‌بایست ضامن تعریف گردد.\"\n",
    "# text3 = \" در سامانه بایگانی الکترونیک سند تایید سند در شعبه تعداد سند را اشتباه نمایش میدهد.\"\n",
    "# text4 = \" در سامانه وندیا شماره شناسه وندیا به صورت N / A نمایش داده می‌شود.\"\n",
    "text = \"متقاضی می‌تواند تسهیلات را بدون ارائه مستند درآمدی به همراه سند ازدواج و شناسنامه و همراه با یک ضامن حقوق‌بگیر دارای گواهی کسر از حقوق دریافت نمایند چنانچه ضامن دوم دارای پروانه‌کسب باشد به شرط دریافت اطلاعات‌اعتباری مورد پذیرش قرار می‌گیرد.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700e4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalizer.normalize('اصلاح نويسه ها و استفاده از نیم‌فاصله پردازش را آسان مي كند')\n",
    "# normalizer.normalize(text2)\n",
    "# 'اصلاح نویسه‌ها و استفاده از نیم‌فاصله پردازش را آسان می‌کند'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627fc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize('ما هم برای وصل کردن آمدیم! ولی برای پردازش، جدا بهتر نیست؟')\n",
    "# ['ما هم برای وصل کردن آمدیم!', 'ولی برای پردازش، جدا بهتر نیست؟']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ae2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# word_tokenize('ولی برای پردازش، جدا بهتر نیست؟')\n",
    "# ['ولی', 'برای', 'پردازش', '،', 'جدا', 'بهتر', 'نیست', '؟']\n",
    "# word_tokenize(text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb317f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \" در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df44717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import POSTagger, word_tokenize\n",
    "\n",
    "# relative to your project root:\n",
    "tagger = POSTagger(model=\"resources/pos_tagger.model\")\n",
    "# print(tagger.tag(word_tokenize(\"ما بسیار کتاب می‌خوانیم\")))\n",
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی وارد شده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec97557",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger_hazm = tagger.tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d1bedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('در', 'ADP'), ('تبادل', 'NOUN,EZ'), ('مانده', 'NOUN,EZ'), ('های', 'NOUN,EZ'), ('انتقالی', 'ADJ'), ('کاربر', 'NOUN'), ('پیغام', 'NOUN'), ('خطای', 'NOUN,EZ'), ('کد', 'NOUN,EZ'), ('ملیتان', 'NOUN'), ('وارد', 'NOUN'), ('شده', 'VERB'), ('را', 'ADP'), ('دریافت', 'NOUN'), ('میکند', 'VERB'), ('و', 'CCONJ'), ('بعد', 'ADP'), ('از', 'ADP'), ('آن', 'PRON'), ('میخواهیم', 'VERB'), ('ببینیم', 'VERB'), ('مساله', 'NOUN'), ('حل', 'NOUN'), ('شده', 'VERB'), ('یا', 'CCONJ'), ('نشده_است', 'VERB'), ('اتمام', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی واردشده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\"\n",
    "\n",
    "print(tagger.tag(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78cbdc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('در', 'ADP'),\n",
       "  ('تبادل', 'NOUN,EZ'),\n",
       "  ('مانده', 'NOUN,EZ'),\n",
       "  ('های', 'NOUN,EZ'),\n",
       "  ('انتقالی', 'ADJ'),\n",
       "  ('کاربر', 'NOUN'),\n",
       "  ('پیغام', 'NOUN'),\n",
       "  ('خطای', 'NOUN,EZ'),\n",
       "  ('کد', 'NOUN,EZ'),\n",
       "  ('ملیتان', 'NOUN'),\n",
       "  ('وارد', 'NOUN'),\n",
       "  ('شده', 'VERB'),\n",
       "  ('را', 'ADP'),\n",
       "  ('دریافت', 'NOUN'),\n",
       "  ('میکند', 'VERB'),\n",
       "  ('و', 'CCONJ'),\n",
       "  ('بعد', 'ADP'),\n",
       "  ('از', 'ADP'),\n",
       "  ('آن', 'PRON'),\n",
       "  ('میخواهیم', 'VERB'),\n",
       "  ('ببینیم', 'VERB'),\n",
       "  ('مساله', 'NOUN'),\n",
       "  ('حل', 'NOUN'),\n",
       "  ('شده', 'VERB'),\n",
       "  ('یا', 'CCONJ'),\n",
       "  ('نشده_است', 'VERB'),\n",
       "  ('اتمام', 'NOUN')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagger.tag_sents(sentences = [['من', 'به', 'مدرسه', 'ایران', 'رفته_بودم', '.']])\n",
    "tagger.tag_sents(sentences = [word_tokenize(text)])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a90295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['در',\n",
       " 'تبادل',\n",
       " 'مانده',\n",
       " 'های',\n",
       " 'انتقالی',\n",
       " 'کاربر',\n",
       " 'پیغام',\n",
       " 'خطای',\n",
       " 'کد',\n",
       " 'ملیتان',\n",
       " 'وارد',\n",
       " 'شده',\n",
       " 'را',\n",
       " 'دریافت',\n",
       " 'میکند',\n",
       " 'و',\n",
       " 'بعد',\n",
       " 'از',\n",
       " 'آن',\n",
       " 'میخواهیم',\n",
       " 'ببینیم',\n",
       " 'مساله',\n",
       " 'حل',\n",
       " 'شده',\n",
       " 'یا',\n",
       " 'نشده_است',\n",
       " 'اتمام']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c0d126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('در', 'ADP'),\n",
       "  ('تبادل', 'NOUN,EZ'),\n",
       "  ('مانده', 'NOUN,EZ'),\n",
       "  ('انتقال', 'NOUN,EZ'),\n",
       "  ('کاربر', 'NOUN'),\n",
       "  ('پیغا', 'NOUN'),\n",
       "  ('خطا', 'NOUN'),\n",
       "  ('کد', 'NOUN,EZ'),\n",
       "  ('مل', 'NOUN'),\n",
       "  ('وارد', 'NOUN'),\n",
       "  ('شده_اس', 'VERB')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag_sents(sentences = [['در',\n",
    " 'تبادل',\n",
    " 'مانده',\n",
    " 'انتقال',\n",
    " 'کاربر',\n",
    " 'پیغا',\n",
    " 'خطا',\n",
    " 'کد',\n",
    " 'مل',\n",
    " 'وارد',\n",
    " 'شده_اس']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdb0bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('در', 'ADP'),\n",
       " ('تبادل', 'NOUN,EZ'),\n",
       " ('مانده', 'NOUN,EZ'),\n",
       " ('های', 'NOUN,EZ'),\n",
       " ('انتقالی', 'ADJ'),\n",
       " ('کاربر', 'NOUN'),\n",
       " ('پیغام', 'NOUN'),\n",
       " ('خطای', 'NOUN,EZ'),\n",
       " ('کد', 'NOUN,EZ'),\n",
       " ('ملیتان', 'NOUN'),\n",
       " ('وارد', 'NOUN'),\n",
       " ('شده', 'VERB'),\n",
       " ('را', 'ADP'),\n",
       " ('دریافت', 'NOUN'),\n",
       " ('میکند', 'VERB'),\n",
       " ('و', 'CCONJ'),\n",
       " ('بعد', 'ADP'),\n",
       " ('از', 'ADP'),\n",
       " ('آن', 'PRON'),\n",
       " ('میخواهیم', 'VERB'),\n",
       " ('ببینیم', 'VERB'),\n",
       " ('مساله', 'NOUN'),\n",
       " ('حل', 'NOUN'),\n",
       " ('شده', 'VERB'),\n",
       " ('یا', 'CCONJ'),\n",
       " ('نشده_است', 'VERB'),\n",
       " ('اتمام', 'NOUN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844ff39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'word': 'در',\n",
       "   'is_first': True,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'د',\n",
       "   'prefix-2': 'در',\n",
       "   'prefix-3': 'در',\n",
       "   'suffix-1': 'ر',\n",
       "   'suffix-2': 'در',\n",
       "   'suffix-3': 'در',\n",
       "   'prev_word': '',\n",
       "   'two_prev_word': '',\n",
       "   'next_word': 'تبادل',\n",
       "   'two_next_word': 'مانده',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': '',\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': '',\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'تبادل',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ت',\n",
       "   'prefix-2': 'تب',\n",
       "   'prefix-3': 'تبا',\n",
       "   'suffix-1': 'ل',\n",
       "   'suffix-2': 'دل',\n",
       "   'suffix-3': 'ادل',\n",
       "   'prev_word': 'در',\n",
       "   'two_prev_word': 'اتمام',\n",
       "   'next_word': 'مانده',\n",
       "   'two_next_word': 'های',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'مانده',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'ما',\n",
       "   'prefix-3': 'مان',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'ده',\n",
       "   'suffix-3': 'نده',\n",
       "   'prev_word': 'تبادل',\n",
       "   'two_prev_word': 'در',\n",
       "   'next_word': 'های',\n",
       "   'two_next_word': 'انتقالی',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'های',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ه',\n",
       "   'prefix-2': 'ها',\n",
       "   'prefix-3': 'های',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'ای',\n",
       "   'suffix-3': 'های',\n",
       "   'prev_word': 'مانده',\n",
       "   'two_prev_word': 'تبادل',\n",
       "   'next_word': 'انتقالی',\n",
       "   'two_next_word': 'کاربر',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'انتقالی',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'ان',\n",
       "   'prefix-3': 'انت',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'لی',\n",
       "   'suffix-3': 'الی',\n",
       "   'prev_word': 'های',\n",
       "   'two_prev_word': 'مانده',\n",
       "   'next_word': 'کاربر',\n",
       "   'two_next_word': 'پیغام',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'کاربر',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ک',\n",
       "   'prefix-2': 'کا',\n",
       "   'prefix-3': 'کار',\n",
       "   'suffix-1': 'ر',\n",
       "   'suffix-2': 'بر',\n",
       "   'suffix-3': 'ربر',\n",
       "   'prev_word': 'انتقالی',\n",
       "   'two_prev_word': 'های',\n",
       "   'next_word': 'پیغام',\n",
       "   'two_next_word': 'خطای',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'پیغام',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'پ',\n",
       "   'prefix-2': 'پی',\n",
       "   'prefix-3': 'پیغ',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'ام',\n",
       "   'suffix-3': 'غام',\n",
       "   'prev_word': 'کاربر',\n",
       "   'two_prev_word': 'انتقالی',\n",
       "   'next_word': 'خطای',\n",
       "   'two_next_word': 'کد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'خطای',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'خ',\n",
       "   'prefix-2': 'خط',\n",
       "   'prefix-3': 'خطا',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'ای',\n",
       "   'suffix-3': 'طای',\n",
       "   'prev_word': 'پیغام',\n",
       "   'two_prev_word': 'کاربر',\n",
       "   'next_word': 'کد',\n",
       "   'two_next_word': 'ملیتان',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'کد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ک',\n",
       "   'prefix-2': 'کد',\n",
       "   'prefix-3': 'کد',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'کد',\n",
       "   'suffix-3': 'کد',\n",
       "   'prev_word': 'خطای',\n",
       "   'two_prev_word': 'پیغام',\n",
       "   'next_word': 'ملیتان',\n",
       "   'two_next_word': 'وارد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'ملیتان',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'مل',\n",
       "   'prefix-3': 'ملی',\n",
       "   'suffix-1': 'ن',\n",
       "   'suffix-2': 'ان',\n",
       "   'suffix-3': 'تان',\n",
       "   'prev_word': 'کد',\n",
       "   'two_prev_word': 'خطای',\n",
       "   'next_word': 'وارد',\n",
       "   'two_next_word': 'شده',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'وارد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'و',\n",
       "   'prefix-2': 'وا',\n",
       "   'prefix-3': 'وار',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'رد',\n",
       "   'suffix-3': 'ارد',\n",
       "   'prev_word': 'ملیتان',\n",
       "   'two_prev_word': 'کد',\n",
       "   'next_word': 'شده',\n",
       "   'two_next_word': 'را',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'شده',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ش',\n",
       "   'prefix-2': 'شد',\n",
       "   'prefix-3': 'شده',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'ده',\n",
       "   'suffix-3': 'شده',\n",
       "   'prev_word': 'وارد',\n",
       "   'two_prev_word': 'ملیتان',\n",
       "   'next_word': 'را',\n",
       "   'two_next_word': 'دریافت',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'را',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ر',\n",
       "   'prefix-2': 'را',\n",
       "   'prefix-3': 'را',\n",
       "   'suffix-1': 'ا',\n",
       "   'suffix-2': 'را',\n",
       "   'suffix-3': 'را',\n",
       "   'prev_word': 'شده',\n",
       "   'two_prev_word': 'وارد',\n",
       "   'next_word': 'دریافت',\n",
       "   'two_next_word': 'میکند',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'دریافت',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'د',\n",
       "   'prefix-2': 'در',\n",
       "   'prefix-3': 'دری',\n",
       "   'suffix-1': 'ت',\n",
       "   'suffix-2': 'فت',\n",
       "   'suffix-3': 'افت',\n",
       "   'prev_word': 'را',\n",
       "   'two_prev_word': 'شده',\n",
       "   'next_word': 'میکند',\n",
       "   'two_next_word': 'و',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'میکند',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'می',\n",
       "   'prefix-3': 'میک',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'ند',\n",
       "   'suffix-3': 'کند',\n",
       "   'prev_word': 'دریافت',\n",
       "   'two_prev_word': 'را',\n",
       "   'next_word': 'و',\n",
       "   'two_next_word': 'بعد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'و',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'و',\n",
       "   'prefix-2': 'و',\n",
       "   'prefix-3': 'و',\n",
       "   'suffix-1': 'و',\n",
       "   'suffix-2': 'و',\n",
       "   'suffix-3': 'و',\n",
       "   'prev_word': 'میکند',\n",
       "   'two_prev_word': 'دریافت',\n",
       "   'next_word': 'بعد',\n",
       "   'two_next_word': 'از',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'بعد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ب',\n",
       "   'prefix-2': 'بع',\n",
       "   'prefix-3': 'بعد',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'عد',\n",
       "   'suffix-3': 'بعد',\n",
       "   'prev_word': 'و',\n",
       "   'two_prev_word': 'میکند',\n",
       "   'next_word': 'از',\n",
       "   'two_next_word': 'آن',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'از',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'از',\n",
       "   'prefix-3': 'از',\n",
       "   'suffix-1': 'ز',\n",
       "   'suffix-2': 'از',\n",
       "   'suffix-3': 'از',\n",
       "   'prev_word': 'بعد',\n",
       "   'two_prev_word': 'و',\n",
       "   'next_word': 'آن',\n",
       "   'two_next_word': 'میخواهیم',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'آن',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'آ',\n",
       "   'prefix-2': 'آن',\n",
       "   'prefix-3': 'آن',\n",
       "   'suffix-1': 'ن',\n",
       "   'suffix-2': 'آن',\n",
       "   'suffix-3': 'آن',\n",
       "   'prev_word': 'از',\n",
       "   'two_prev_word': 'بعد',\n",
       "   'next_word': 'میخواهیم',\n",
       "   'two_next_word': 'ببینیم',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'میخواهیم',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'می',\n",
       "   'prefix-3': 'میخ',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'یم',\n",
       "   'suffix-3': 'هیم',\n",
       "   'prev_word': 'آن',\n",
       "   'two_prev_word': 'از',\n",
       "   'next_word': 'ببینیم',\n",
       "   'two_next_word': 'مساله',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'ببینیم',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ب',\n",
       "   'prefix-2': 'بب',\n",
       "   'prefix-3': 'ببی',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'یم',\n",
       "   'suffix-3': 'نیم',\n",
       "   'prev_word': 'میخواهیم',\n",
       "   'two_prev_word': 'آن',\n",
       "   'next_word': 'مساله',\n",
       "   'two_next_word': 'حل',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'مساله',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'مس',\n",
       "   'prefix-3': 'مسا',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'له',\n",
       "   'suffix-3': 'اله',\n",
       "   'prev_word': 'ببینیم',\n",
       "   'two_prev_word': 'میخواهیم',\n",
       "   'next_word': 'حل',\n",
       "   'two_next_word': 'شده',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'حل',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ح',\n",
       "   'prefix-2': 'حل',\n",
       "   'prefix-3': 'حل',\n",
       "   'suffix-1': 'ل',\n",
       "   'suffix-2': 'حل',\n",
       "   'suffix-3': 'حل',\n",
       "   'prev_word': 'مساله',\n",
       "   'two_prev_word': 'ببینیم',\n",
       "   'next_word': 'شده',\n",
       "   'two_next_word': 'یا',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'شده',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ش',\n",
       "   'prefix-2': 'شد',\n",
       "   'prefix-3': 'شده',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'ده',\n",
       "   'suffix-3': 'شده',\n",
       "   'prev_word': 'حل',\n",
       "   'two_prev_word': 'مساله',\n",
       "   'next_word': 'یا',\n",
       "   'two_next_word': 'نشده_است',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'یا',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ی',\n",
       "   'prefix-2': 'یا',\n",
       "   'prefix-3': 'یا',\n",
       "   'suffix-1': 'ا',\n",
       "   'suffix-2': 'یا',\n",
       "   'suffix-3': 'یا',\n",
       "   'prev_word': 'شده',\n",
       "   'two_prev_word': 'حل',\n",
       "   'next_word': 'نشده_است',\n",
       "   'two_next_word': 'اتمام',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'نشده_است',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ن',\n",
       "   'prefix-2': 'نش',\n",
       "   'prefix-3': 'نشد',\n",
       "   'suffix-1': 'ت',\n",
       "   'suffix-2': 'ست',\n",
       "   'suffix-3': 'است',\n",
       "   'prev_word': 'یا',\n",
       "   'two_prev_word': 'شده',\n",
       "   'next_word': 'اتمام',\n",
       "   'two_next_word': '',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'اتمام',\n",
       "   'is_first': False,\n",
       "   'is_last': True,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'ات',\n",
       "   'prefix-3': 'اتم',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'ام',\n",
       "   'suffix-3': 'مام',\n",
       "   'prev_word': 'نشده_است',\n",
       "   'two_prev_word': 'یا',\n",
       "   'next_word': '',\n",
       "   'two_next_word': '',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': '',\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': ''}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_text = tagger.data_maker(tokens = [word_tokenize(text)])\n",
    "details_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6e734f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شده\n",
      "وارد\n"
     ]
    }
   ],
   "source": [
    "next_word = details_text[0][11-1].get(\"next_word\")\n",
    "own_word = details_text[0][11-1].get(\"word\")\n",
    "print(next_word)\n",
    "print(own_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfecf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_text = tagger.data_maker(tokens = [word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bcf8ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'در',\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'د',\n",
       "  'prefix-2': 'در',\n",
       "  'prefix-3': 'در',\n",
       "  'suffix-1': 'ر',\n",
       "  'suffix-2': 'در',\n",
       "  'suffix-3': 'در',\n",
       "  'prev_word': '',\n",
       "  'two_prev_word': '',\n",
       "  'next_word': 'تبادل',\n",
       "  'two_next_word': 'مانده',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': '',\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': '',\n",
       "  'next_is_punc': False},\n",
       " {'word': 'تبادل',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ت',\n",
       "  'prefix-2': 'تب',\n",
       "  'prefix-3': 'تبا',\n",
       "  'suffix-1': 'ل',\n",
       "  'suffix-2': 'دل',\n",
       "  'suffix-3': 'ادل',\n",
       "  'prev_word': 'در',\n",
       "  'two_prev_word': 'شده',\n",
       "  'next_word': 'مانده',\n",
       "  'two_next_word': 'های',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'مانده',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'ما',\n",
       "  'prefix-3': 'مان',\n",
       "  'suffix-1': 'ه',\n",
       "  'suffix-2': 'ده',\n",
       "  'suffix-3': 'نده',\n",
       "  'prev_word': 'تبادل',\n",
       "  'two_prev_word': 'در',\n",
       "  'next_word': 'های',\n",
       "  'two_next_word': 'انتقالی',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'های',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ه',\n",
       "  'prefix-2': 'ها',\n",
       "  'prefix-3': 'های',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'ای',\n",
       "  'suffix-3': 'های',\n",
       "  'prev_word': 'مانده',\n",
       "  'two_prev_word': 'تبادل',\n",
       "  'next_word': 'انتقالی',\n",
       "  'two_next_word': 'کاربر',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'انتقالی',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ا',\n",
       "  'prefix-2': 'ان',\n",
       "  'prefix-3': 'انت',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'لی',\n",
       "  'suffix-3': 'الی',\n",
       "  'prev_word': 'های',\n",
       "  'two_prev_word': 'مانده',\n",
       "  'next_word': 'کاربر',\n",
       "  'two_next_word': 'پیغام',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'کاربر',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ک',\n",
       "  'prefix-2': 'کا',\n",
       "  'prefix-3': 'کار',\n",
       "  'suffix-1': 'ر',\n",
       "  'suffix-2': 'بر',\n",
       "  'suffix-3': 'ربر',\n",
       "  'prev_word': 'انتقالی',\n",
       "  'two_prev_word': 'های',\n",
       "  'next_word': 'پیغام',\n",
       "  'two_next_word': 'خطای',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'پیغام',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'پ',\n",
       "  'prefix-2': 'پی',\n",
       "  'prefix-3': 'پیغ',\n",
       "  'suffix-1': 'م',\n",
       "  'suffix-2': 'ام',\n",
       "  'suffix-3': 'غام',\n",
       "  'prev_word': 'کاربر',\n",
       "  'two_prev_word': 'انتقالی',\n",
       "  'next_word': 'خطای',\n",
       "  'two_next_word': 'کد',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'خطای',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'خ',\n",
       "  'prefix-2': 'خط',\n",
       "  'prefix-3': 'خطا',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'ای',\n",
       "  'suffix-3': 'طای',\n",
       "  'prev_word': 'پیغام',\n",
       "  'two_prev_word': 'کاربر',\n",
       "  'next_word': 'کد',\n",
       "  'two_next_word': 'ملیتان',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'کد',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ک',\n",
       "  'prefix-2': 'کد',\n",
       "  'prefix-3': 'کد',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'کد',\n",
       "  'suffix-3': 'کد',\n",
       "  'prev_word': 'خطای',\n",
       "  'two_prev_word': 'پیغام',\n",
       "  'next_word': 'ملیتان',\n",
       "  'two_next_word': 'وارد',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'ملیتان',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'مل',\n",
       "  'prefix-3': 'ملی',\n",
       "  'suffix-1': 'ن',\n",
       "  'suffix-2': 'ان',\n",
       "  'suffix-3': 'تان',\n",
       "  'prev_word': 'کد',\n",
       "  'two_prev_word': 'خطای',\n",
       "  'next_word': 'وارد',\n",
       "  'two_next_word': 'شده',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'وارد',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'و',\n",
       "  'prefix-2': 'وا',\n",
       "  'prefix-3': 'وار',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'رد',\n",
       "  'suffix-3': 'ارد',\n",
       "  'prev_word': 'ملیتان',\n",
       "  'two_prev_word': 'کد',\n",
       "  'next_word': 'شده',\n",
       "  'two_next_word': '',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'شده',\n",
       "  'is_first': False,\n",
       "  'is_last': True,\n",
       "  'prefix-1': 'ش',\n",
       "  'prefix-2': 'شد',\n",
       "  'prefix-3': 'شده',\n",
       "  'suffix-1': 'ه',\n",
       "  'suffix-2': 'ده',\n",
       "  'suffix-3': 'شده',\n",
       "  'prev_word': 'وارد',\n",
       "  'two_prev_word': 'ملیتان',\n",
       "  'next_word': '',\n",
       "  'two_next_word': '',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': '',\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': ''}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c9c62",
   "metadata": {},
   "source": [
    "# Test parsivar for pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f7fe58",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the /home/mahdi/word_embedding_Narenjestan/resources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/models/farsi.tagger file!\nUse software specific configuration parameters or set the STANFORD_MODELS environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mparsivar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m POSTagger\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m my_tagger = \u001b[43mPOSTagger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtagging_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstanford\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstanford_postagger_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/mahdi/word_embedding_Narenjestan/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/models/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfarsi.tagger\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjar_tagger_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/mahdi/word_embedding_Narenjestan/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/stanford-postagger.jar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjdk_variable_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/usr/lib/jvm/java-11-openjdk-amd64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mاین سمینار تا 13 شهریور ادامه می‌یابد .\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m tags = my_tagger.parse(my_tokenizer.tokenize_words(text))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/parsivar/postagger.py:40\u001b[39m, in \u001b[36mPOSTagger.__init__\u001b[39m\u001b[34m(self, stanford_postagger_model, wapiti_postagger_model, jar_tagger_path, jdk_variable_path, tagging_model)\u001b[39m\n\u001b[32m     37\u001b[39m     java_path = jdk_variable_path\n\u001b[32m     38\u001b[39m     os.environ[\u001b[33m'\u001b[39m\u001b[33mJAVAHOME\u001b[39m\u001b[33m'\u001b[39m] = java_path\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28mself\u001b[39m.tagger = \u001b[43mStanfordPOSTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstanford_postagger_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mpath_to_jar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjar_tagger_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-mx5000m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tagging_model == \u001b[33m\"\u001b[39m\u001b[33mwapiti\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwapiti\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/nltk/tag/stanford.py:159\u001b[39m, in \u001b[36mStanfordPOSTagger.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/nltk/tag/stanford.py:74\u001b[39m, in \u001b[36mStanfordTagger.__init__\u001b[39m\u001b[34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[39m\n\u001b[32m     65\u001b[39m     warnings.warn(\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe StanfordTagger class is not meant to be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minstantiated directly. Did you mean \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mStanfordPOSTagger or StanfordNERTagger?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m     )\n\u001b[32m     70\u001b[39m \u001b[38;5;28mself\u001b[39m._stanford_jar = find_jar(\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m._JAR, path_to_jar, searchpath=(), url=_stanford_url, verbose=verbose\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28mself\u001b[39m._stanford_model = \u001b[43mfind_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSTANFORD_MODELS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._encoding = encoding\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m.java_options = java_options\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/nltk/internals.py:628\u001b[39m, in \u001b[36mfind_file\u001b[39m\u001b[34m(filename, env_vars, searchpath, file_names, url, verbose)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_file\u001b[39m(\n\u001b[32m    626\u001b[39m     filename, env_vars=(), searchpath=(), file_names=\u001b[38;5;28;01mNone\u001b[39;00m, url=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    627\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfind_file_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearchpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/nltk/internals.py:622\u001b[39m, in \u001b[36mfind_file_iter\u001b[39m\u001b[34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[39m\n\u001b[32m    620\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  For more information on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    <\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    621\u001b[39m div = \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m75\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLookupError\u001b[39m: \n\n===========================================================================\nNLTK was unable to find the /home/mahdi/word_embedding_Narenjestan/resources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/models/farsi.tagger file!\nUse software specific configuration parameters or set the STANFORD_MODELS environment variable.\n==========================================================================="
     ]
    }
   ],
   "source": [
    "from parsivar import POSTagger\n",
    "\n",
    "my_tagger = POSTagger(\n",
    "    tagging_model=\"stanford\",\n",
    "    stanford_postagger_model=(\n",
    "        \"/home/mahdi/word_embedding_Narenjestan/\"\n",
    "        \"resources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/models/\"\n",
    "        \"farsi.tagger\"\n",
    "    ),\n",
    "    jar_tagger_path=(\n",
    "        \"/home/mahdi/word_embedding_Narenjestan/\"\n",
    "        \"resources/stanford-tagger-4.2.0/stanford-postagger-full-2020-11-17/stanford-postagger.jar\"\n",
    "    ),\n",
    "    jdk_variable_path=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    ")\n",
    "\n",
    "text = \"این سمینار تا 13 شهریور ادامه می‌یابد .\"\n",
    "tags = my_tagger.parse(my_tokenizer.tokenize_words(text))\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6799034",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mparsivar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m POSTagger\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m my_tagger = \u001b[43mPOSTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagging_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwapiti\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# tagging_model = \"wapiti\" or \"stanford\". \"wapiti\" is faster than \"stanford\"\u001b[39;00m\n\u001b[32m      3\u001b[39m text_tags = my_tagger.parse(my_tokenizer.tokenize_words(\u001b[33m\"\u001b[39m\u001b[33mاین سمینار تا 13 شهریور ادامه می‌یابد .\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(text_tags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/parsivar/postagger.py:45\u001b[39m, in \u001b[36mPOSTagger.__init__\u001b[39m\u001b[34m(self, stanford_postagger_model, wapiti_postagger_model, jar_tagger_path, jdk_variable_path, tagging_model)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m.tagger = StanfordPOSTagger(model_filename=\u001b[38;5;28mself\u001b[39m.stanford_postagger_model,\n\u001b[32m     41\u001b[39m                                     path_to_jar=\u001b[38;5;28mself\u001b[39m.jar_tagger_path,\n\u001b[32m     42\u001b[39m                                     encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     43\u001b[39m                                     java_options=\u001b[33m'\u001b[39m\u001b[33m-mx5000m\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tagging_model == \u001b[33m\"\u001b[39m\u001b[33mwapiti\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwapiti\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.tagger = Model(model=\u001b[38;5;28mself\u001b[39m.wapiti_postagger_model)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "from parsivar import POSTagger\n",
    "my_tagger = POSTagger(tagging_model=\"wapiti\")  # tagging_model = \"wapiti\" or \"stanford\". \"wapiti\" is faster than \"stanford\"\n",
    "text_tags = my_tagger.parse(my_tokenizer.tokenize_words(\"این سمینار تا 13 شهریور ادامه می‌یابد .\"))\n",
    "print(text_tags)\n",
    "# [('این', 'DET'), ('سمینار', 'N_SING'), ('تا', 'P'), ('13', 'NUM'), ('شهریور', 'N_SING'), ('ادامه', 'N_SING'), ('می\\u200cیابد', 'V_PRS'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618bc2e",
   "metadata": {},
   "source": [
    "## Test POS tagging Dadmatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48e9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی وارد شده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\"\n",
    "# text = \"در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده \"\n",
    "# text2 = \" درخواست خدمت اعتباری تغییر ضامن پیغام خطای مصوبه فوق فاقد وثیقه ضامن پذیر است دریافت می‌گردد چاپ مجدد پیشنهاد بررسی گردد در صورتی که تیک قرارداد لازم اجرا ثبت شده باشد می‌بایست ضامن تعریف گردد.\"\n",
    "# text3 = \" در سامانه بایگانی الکترونیک سند تایید سند در شعبه تعداد سند را اشتباه نمایش میدهد.\"\n",
    "# text4 = \" در سامانه وندیا شماره شناسه وندیا به صورت N / A نمایش داده می‌شود.\"\n",
    "text = \" در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است. اتمام \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbc37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 5.07M/5.07M [00:03<00:00, 1.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained XLM-Roberta, this may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 512/512 [00:00<00:00, 682kB/s]\n",
      "Downloading file cache/dadmatools/fa_tokenizer.pt: : 639kB [00:03, 169kB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer for persian\n",
      "Loading tagger for persian\n",
      "Loading multi-word expander for persian\n",
      "Loading lemmatizer for persian\n",
      "Loading NER tagger for persian\n",
      "Loading Kasreh tagger for persian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Active language: persian\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 15.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "\n",
    "# here lemmatizer and pos tagger will be loaded\n",
    "# as tokenizer is the default tool, it will be loaded as well even without calling\n",
    "pips = 'tok,lem,pos,dep,chunk,cons,spellchecker,kasreh,itf,ner,sent'\n",
    "nlp = language.Pipeline(pips)\n",
    "# doc is now a proper spaCy Doc object\n",
    "doc = nlp(text)\n",
    "# doc = nlp('کشور بزرگ ایران توانسته در طی سال‌ها اقشار مختلفی از قومیت‌های گوناگون را به خوبی در خودش جا بده')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9468110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "متقاضی NOUN N_SING\n",
      "می‌تواند VERB V_PRS\n",
      "تسهیلات NOUN N_SING\n",
      "را PART CLITIC\n",
      "بدون NOUN N_SING\n",
      "ارائه NOUN N_SING\n",
      "مستند NOUN N_SING\n",
      "درآمدی NOUN N_SING\n",
      "به ADP P\n",
      "همراه NOUN N_SING\n",
      "سند NOUN N_SING\n",
      "ازدواج NOUN N_SING\n",
      "و CCONJ CON\n",
      "شناسنامه NOUN N_SING\n",
      "و CCONJ CON\n",
      "همراه NOUN N_SING\n",
      "با ADP P\n",
      "یک NUM NUM\n",
      "ضامن NOUN N_SING\n",
      "حقوق‌بگیر NOUN N_SING\n",
      "دارای ADJ ADJ\n",
      "گواهی NOUN N_SING\n",
      "کسر NOUN N_SING\n",
      "از ADP P\n",
      "حقوق NOUN N_SING\n",
      "دریافت NOUN N_SING\n",
      "نمایند VERB V_SUB\n",
      "چنانچه NOUN N_SING\n",
      "ضامن NOUN N_SING\n",
      "دوم NOUN N_SING\n",
      "دارای ADJ ADJ\n",
      "پروانه‌کسب NOUN N_SING\n",
      "باشد VERB V_SUB\n",
      "به ADP P\n",
      "شرط NOUN N_SING\n",
      "دریافت NOUN N_SING\n",
      "اطلاعات‌اعتباری NOUN N_SING\n",
      "مورد NOUN N_SING\n",
      "پذیرش NOUN N_SING\n",
      "قرار NOUN N_SING\n",
      "می‌گیرد VERB V_PRS\n",
      ". PUNCT DELM\n"
     ]
    }
   ],
   "source": [
    "for token_dadmatools in doc:\n",
    "    print(token_dadmatools.text, token_dadmatools.pos_, token_dadmatools.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9dbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"متقاضی می‌تواند تسهیلات را بدون ارائه مستند درآمدی به همراه سند ازدواج و شناسنامه و همراه با یک ضامن حقوق‌بگیر دارای گواهی کسر از حقوق دریافت نمایند چنانچه ضامن دوم دارای پروانه‌کسب باشد به شرط دریافت اطلاعات‌اعتباری مورد پذیرش قرار می‌گیرد.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b997bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained XLM-Roberta, this may take a while...\n",
      "Model fa_tokenizer exists in cache/dadmatools/fa_tokenizer.pt\n",
      "Loading tokenizer for persian\n",
      "Loading tagger for persian\n",
      "Loading multi-word expander for persian\n",
      "==================================================\n",
      "Active language: persian\n",
      "==================================================\n",
      "متقاضی NOUN N_SING\n",
      "می‌تواند VERB V_PRS\n",
      "تسهیلات NOUN N_SING\n",
      "را PART CLITIC\n",
      "بدون NOUN N_SING\n",
      "ارائه NOUN N_SING\n",
      "مستند NOUN N_SING\n",
      "درآمدی NOUN N_SING\n",
      "به ADP P\n",
      "همراه NOUN N_SING\n",
      "سند NOUN N_SING\n",
      "ازدواج NOUN N_SING\n",
      "و CCONJ CON\n",
      "شناسنامه NOUN N_SING\n",
      "و CCONJ CON\n",
      "همراه NOUN N_SING\n",
      "با ADP P\n",
      "یک NUM NUM\n",
      "ضامن NOUN N_SING\n",
      "حقوق‌بگیر NOUN N_SING\n",
      "دارای ADJ ADJ\n",
      "گواهی VERB V_PRS\n",
      "کسر NOUN N_SING\n",
      "از ADP P\n",
      "حقوق NOUN N_SING\n",
      "دریافت NOUN N_SING\n",
      "نمایند VERB V_SUB\n",
      "چنانچه CCONJ CON\n",
      "ضامن NOUN N_SING\n",
      "دوم NOUN N_SING\n",
      "دارای ADJ ADJ\n",
      "پروانه‌کسب NOUN N_SING\n",
      "باشد VERB V_SUB\n",
      "به ADP P\n",
      "شرط NOUN N_SING\n",
      "دریافت NOUN N_SING\n",
      "اطلاعات‌اعتباری NOUN N_SING\n",
      "مورد NOUN N_SING\n",
      "پذیرش NOUN N_SING\n",
      "قرار NOUN N_SING\n",
      "می‌گیرد VERB V_PRS\n",
      ". PUNCT DELM\n"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "\n",
    "# here lemmatizer and pos tagger will be loaded\n",
    "# as tokenizer is the default tool, it will be loaded as well even without calling\n",
    "pips = 'pos'\n",
    "nlp = language.Pipeline(pips)\n",
    "# doc is now a proper spaCy Doc object\n",
    "doc = nlp(text)\n",
    "\n",
    "total_token_pos_tag_dadma = []\n",
    "\n",
    "for token_dadmatools in doc:\n",
    "    token_dadma =token_dadmatools.text\n",
    "    pos_dadma = token_dadmatools.pos_\n",
    "    pos_tag_dadma = token_dadmatools.tag_\n",
    "    total_token_pos_tag_dadma.append((token_dadma,pos_dadma,pos_tag_dadma))\n",
    "    print(token_dadmatools.text, token_dadmatools.pos_, token_dadmatools.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2839a5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('متقاضی', 'NOUN', 'N_SING'),\n",
       " ('می\\u200cتواند', 'VERB', 'V_PRS'),\n",
       " ('تسهیلات', 'NOUN', 'N_SING'),\n",
       " ('را', 'PART', 'CLITIC'),\n",
       " ('بدون', 'NOUN', 'N_SING'),\n",
       " ('ارائه', 'NOUN', 'N_SING'),\n",
       " ('مستند', 'NOUN', 'N_SING'),\n",
       " ('درآمدی', 'NOUN', 'N_SING'),\n",
       " ('به', 'ADP', 'P'),\n",
       " ('همراه', 'NOUN', 'N_SING'),\n",
       " ('سند', 'NOUN', 'N_SING'),\n",
       " ('ازدواج', 'NOUN', 'N_SING'),\n",
       " ('و', 'CCONJ', 'CON'),\n",
       " ('شناسنامه', 'NOUN', 'N_SING'),\n",
       " ('و', 'CCONJ', 'CON'),\n",
       " ('همراه', 'NOUN', 'N_SING'),\n",
       " ('با', 'ADP', 'P'),\n",
       " ('یک', 'NUM', 'NUM'),\n",
       " ('ضامن', 'NOUN', 'N_SING'),\n",
       " ('حقوق\\u200cبگیر', 'NOUN', 'N_SING'),\n",
       " ('دارای', 'ADJ', 'ADJ'),\n",
       " ('گواهی', 'VERB', 'V_PRS'),\n",
       " ('کسر', 'NOUN', 'N_SING'),\n",
       " ('از', 'ADP', 'P'),\n",
       " ('حقوق', 'NOUN', 'N_SING'),\n",
       " ('دریافت', 'NOUN', 'N_SING'),\n",
       " ('نمایند', 'VERB', 'V_SUB'),\n",
       " ('چنانچه', 'CCONJ', 'CON'),\n",
       " ('ضامن', 'NOUN', 'N_SING'),\n",
       " ('دوم', 'NOUN', 'N_SING'),\n",
       " ('دارای', 'ADJ', 'ADJ'),\n",
       " ('پروانه\\u200cکسب', 'NOUN', 'N_SING'),\n",
       " ('باشد', 'VERB', 'V_SUB'),\n",
       " ('به', 'ADP', 'P'),\n",
       " ('شرط', 'NOUN', 'N_SING'),\n",
       " ('دریافت', 'NOUN', 'N_SING'),\n",
       " ('اطلاعات\\u200cاعتباری', 'NOUN', 'N_SING'),\n",
       " ('مورد', 'NOUN', 'N_SING'),\n",
       " ('پذیرش', 'NOUN', 'N_SING'),\n",
       " ('قرار', 'NOUN', 'N_SING'),\n",
       " ('می\\u200cگیرد', 'VERB', 'V_PRS'),\n",
       " ('.', 'PUNCT', 'DELM')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_token_pos_tag_dadma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f010dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_token_pos_tag_dadma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28993d5",
   "metadata": {},
   "source": [
    "### Compare Pos tagging in Hazm and dadmatools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1142185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('متقاضی', 'NOUN'),\n",
       " ('می\\u200cتواند', 'VERB'),\n",
       " ('تسهیلات', 'NOUN'),\n",
       " ('را', 'ADP'),\n",
       " ('بدون', 'ADP,EZ'),\n",
       " ('ارائه', 'NOUN,EZ'),\n",
       " ('مستند', 'NOUN,EZ'),\n",
       " ('درآمدی', 'ADJ'),\n",
       " ('به', 'ADP'),\n",
       " ('همراه', 'NOUN,EZ'),\n",
       " ('سند', 'NOUN,EZ'),\n",
       " ('ازدواج', 'NOUN'),\n",
       " ('و', 'CCONJ'),\n",
       " ('شناسنامه', 'NOUN'),\n",
       " ('و', 'CCONJ'),\n",
       " ('همراه', 'NOUN'),\n",
       " ('با', 'ADP'),\n",
       " ('یک', 'NUM'),\n",
       " ('ضامن', 'NOUN,EZ'),\n",
       " ('حقوق\\u200cبگیر', 'ADJ'),\n",
       " ('دارای', 'ADJ,EZ'),\n",
       " ('گواهی', 'NOUN,EZ'),\n",
       " ('کسر', 'NOUN'),\n",
       " ('از', 'ADP'),\n",
       " ('حقوق', 'NOUN'),\n",
       " ('دریافت', 'NOUN'),\n",
       " ('نمایند', 'VERB'),\n",
       " ('چنانچه', 'SCONJ'),\n",
       " ('ضامن', 'NOUN,EZ'),\n",
       " ('دوم', 'ADJ'),\n",
       " ('دارای', 'ADJ,EZ'),\n",
       " ('پروانه\\u200cکسب', 'NOUN'),\n",
       " ('باشد', 'VERB'),\n",
       " ('به', 'ADP'),\n",
       " ('شرط', 'NOUN,EZ'),\n",
       " ('دریافت', 'NOUN,EZ'),\n",
       " ('اطلاعات\\u200cاعتباری', 'NOUN'),\n",
       " ('مورد', 'NOUN,EZ'),\n",
       " ('پذیرش', 'NOUN'),\n",
       " ('قرار', 'NOUN'),\n",
       " ('می\\u200cگیرد', 'VERB'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger_hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdfa3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tagger_hazm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e9e10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger_chatgpt_list= [\n",
    "    (\"متقاضی\", \"NOUN\"),\n",
    "    (\"می‌تواند\", \"VERB\"),\n",
    "    (\"تسهیلات\", \"NOUN\"),\n",
    "    (\"را\", \"ADP\"),\n",
    "    (\"بدون\", \"ADP\"),\n",
    "    (\"ارائه\", \"NOUN\"),\n",
    "    (\"مستند\", \"ADJ\"),\n",
    "    (\"درآمدی\", \"ADJ\"),\n",
    "    (\"به\", \"ADP\"),\n",
    "    (\"همراه\", \"NOUN\"),\n",
    "    (\"سند\", \"NOUN\"),\n",
    "    (\"ازدواج\", \"NOUN\"),\n",
    "    (\"و\", \"CCONJ\"),\n",
    "    (\"شناسنامه\", \"NOUN\"),\n",
    "    (\"و\", \"CCONJ\"),\n",
    "    (\"همراه\", \"NOUN\"),\n",
    "    (\"با\", \"ADP\"),\n",
    "    (\"یک\", \"NUM\"),\n",
    "    (\"ضامن\", \"NOUN\"),\n",
    "    (\"حقوق‌بگیر\", \"ADJ\"),\n",
    "    (\"دارای\", \"ADJ\"),\n",
    "    (\"گواهی\", \"NOUN\"),\n",
    "    (\"کسر\", \"NOUN\"),\n",
    "    (\"از\", \"ADP\"),\n",
    "    (\"حقوق\", \"NOUN\"),\n",
    "    (\"دریافت\", \"VERB\"),\n",
    "    (\"نمایند\", \"VERB\"),\n",
    "    (\"چنانچه\", \"SCONJ\"),\n",
    "    (\"ضامن\", \"NOUN\"),\n",
    "    (\"دوم\", \"ADJ\"),\n",
    "    (\"دارای\", \"ADJ\"),\n",
    "    (\"پروانه‌کسب\", \"NOUN\"),\n",
    "    (\"باشد\", \"VERB\"),\n",
    "    (\"به\", \"ADP\"),\n",
    "    (\"شرط\", \"NOUN\"),\n",
    "    (\"دریافت\", \"NOUN\"),\n",
    "    (\"اطلاعات‌اعتباری\", \"NOUN\"),\n",
    "    (\"مورد\", \"NOUN\"),\n",
    "    (\"پذیرش\", \"NOUN\"),\n",
    "    (\"قرار\", \"NOUN\"),\n",
    "    (\"می‌گیرد\", \"VERB\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afa3949d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>hazm_pos</th>\n",
       "      <th>gpt_pos</th>\n",
       "      <th>dadma_upos</th>\n",
       "      <th>dadma_xpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>متقاضی</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>می‌تواند</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>V_PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تسهیلات</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>را</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PART</td>\n",
       "      <td>CLITIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>بدون</td>\n",
       "      <td>ADP,EZ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ارائه</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>مستند</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>درآمدی</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>به</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>همراه</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>سند</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ازدواج</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>و</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>شناسنامه</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>و</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>همراه</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>با</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>یک</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ضامن</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>حقوق‌بگیر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>دارای</td>\n",
       "      <td>ADJ,EZ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>گواهی</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>V_PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>کسر</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>از</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>حقوق</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>دریافت</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>نمایند</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>V_SUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>چنانچه</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ضامن</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>دوم</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>دارای</td>\n",
       "      <td>ADJ,EZ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>پروانه‌کسب</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>باشد</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>V_SUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>به</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>شرط</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>دریافت</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>اطلاعات‌اعتباری</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>مورد</td>\n",
       "      <td>NOUN,EZ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>پذیرش</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>قرار</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>N_SING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>می‌گیرد</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>V_PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DELM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token hazm_pos gpt_pos dadma_upos dadma_xpos\n",
       "0            متقاضی     NOUN    NOUN       NOUN     N_SING\n",
       "1          می‌تواند     VERB    VERB       VERB      V_PRS\n",
       "2           تسهیلات     NOUN    NOUN       NOUN     N_SING\n",
       "3                را      ADP     ADP       PART     CLITIC\n",
       "4              بدون   ADP,EZ     ADP       NOUN     N_SING\n",
       "5             ارائه  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "6             مستند  NOUN,EZ     ADJ       NOUN     N_SING\n",
       "7            درآمدی      ADJ     ADJ       NOUN     N_SING\n",
       "8                به      ADP     ADP        ADP          P\n",
       "9             همراه  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "10              سند  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "11           ازدواج     NOUN    NOUN       NOUN     N_SING\n",
       "12                و    CCONJ   CCONJ      CCONJ        CON\n",
       "13         شناسنامه     NOUN    NOUN       NOUN     N_SING\n",
       "14                و    CCONJ   CCONJ      CCONJ        CON\n",
       "15            همراه     NOUN    NOUN       NOUN     N_SING\n",
       "16               با      ADP     ADP        ADP          P\n",
       "17               یک      NUM     NUM        NUM        NUM\n",
       "18             ضامن  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "19        حقوق‌بگیر      ADJ     ADJ       NOUN     N_SING\n",
       "20            دارای   ADJ,EZ     ADJ        ADJ        ADJ\n",
       "21            گواهی  NOUN,EZ    NOUN       VERB      V_PRS\n",
       "22              کسر     NOUN    NOUN       NOUN     N_SING\n",
       "23               از      ADP     ADP        ADP          P\n",
       "24             حقوق     NOUN    NOUN       NOUN     N_SING\n",
       "25           دریافت     NOUN    VERB       NOUN     N_SING\n",
       "26           نمایند     VERB    VERB       VERB      V_SUB\n",
       "27           چنانچه    SCONJ   SCONJ      CCONJ        CON\n",
       "28             ضامن  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "29              دوم      ADJ     ADJ       NOUN     N_SING\n",
       "30            دارای   ADJ,EZ     ADJ        ADJ        ADJ\n",
       "31       پروانه‌کسب     NOUN    NOUN       NOUN     N_SING\n",
       "32             باشد     VERB    VERB       VERB      V_SUB\n",
       "33               به      ADP     ADP        ADP          P\n",
       "34              شرط  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "35           دریافت  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "36  اطلاعات‌اعتباری     NOUN    NOUN       NOUN     N_SING\n",
       "37             مورد  NOUN,EZ    NOUN       NOUN     N_SING\n",
       "38            پذیرش     NOUN    NOUN       NOUN     N_SING\n",
       "39             قرار     NOUN    NOUN       NOUN     N_SING\n",
       "40          می‌گیرد     VERB    VERB       VERB      V_PRS\n",
       "41                .    PUNCT     NaN      PUNCT       DELM"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hazm_list = pos_tagger_hazm\n",
    "dadma_list = total_token_pos_tag_dadma\n",
    "\n",
    "# --- Convert lists to DataFrames ---\n",
    "df_hazm = pd.DataFrame(hazm_list, columns=[\"token\", \"hazm_pos\"])\n",
    "df_dadma = pd.DataFrame(dadma_list, columns=[\"token\", \"dadma_upos\", \"dadma_xpos\"])\n",
    "df_gpt = pd.DataFrame(pos_tagger_chatgpt_list, columns=[\"token\", \"gpt_pos\"])\n",
    "\n",
    "# --- Merge DataFrames on token (same order, same token) ---\n",
    "df = pd.concat([df_hazm, df_gpt[\"gpt_pos\"], df_dadma[[\"dadma_upos\", \"dadma_xpos\"]]], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7530a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"MEC-pos_comparison_Hazm_GPT_Dadmatools-V0.1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433cc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11-hazm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
