{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea5a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240087ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی وارد شده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\"\n",
    "text = \"در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده \"\n",
    "# text2 = \" درخواست خدمت اعتباری تغییر ضامن پیغام خطای مصوبه فوق فاقد وثیقه ضامن پذیر است دریافت می‌گردد چاپ مجدد پیشنهاد بررسی گردد در صورتی که تیک قرارداد لازم اجرا ثبت شده باشد می‌بایست ضامن تعریف گردد.\"\n",
    "# text3 = \" در سامانه بایگانی الکترونیک سند تایید سند در شعبه تعداد سند را اشتباه نمایش میدهد.\"\n",
    "# text4 = \" در سامانه وندیا شماره شناسه وندیا به صورت N / A نمایش داده می‌شود.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700e4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalizer.normalize('اصلاح نويسه ها و استفاده از نیم‌فاصله پردازش را آسان مي كند')\n",
    "# normalizer.normalize(text2)\n",
    "# 'اصلاح نویسه‌ها و استفاده از نیم‌فاصله پردازش را آسان می‌کند'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627fc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize('ما هم برای وصل کردن آمدیم! ولی برای پردازش، جدا بهتر نیست؟')\n",
    "# ['ما هم برای وصل کردن آمدیم!', 'ولی برای پردازش، جدا بهتر نیست؟']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ae2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# word_tokenize('ولی برای پردازش، جدا بهتر نیست؟')\n",
    "# ['ولی', 'برای', 'پردازش', '،', 'جدا', 'بهتر', 'نیست', '؟']\n",
    "# word_tokenize(text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb317f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddafc362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در         → در\n",
      "تبادل      → تبادل\n",
      "مانده‌های  → مانده\n",
      "انتقالی    → انتقالی\n",
      "کاربر      → کاربر\n",
      "پیغام      → پیغام\n",
      "خطای       → خطای\n",
      "کد         → کد\n",
      "ملیتان     → مل\n",
      "وارد       → وارد\n",
      "شده        → شده\n",
      "را         → را\n",
      "دریافت     → دریافت\n",
      "می‌کند     → کرد#کن\n",
      "و          → و\n",
      "بعد        → بعد\n",
      "از         → از\n",
      "آن         → آن\n",
      "می‌خواهیم  → خواست#خواه\n",
      "ببینیم     → دید#بین\n",
      "مساله      → مساله\n",
      "حل‌شده     → حل‌شده\n",
      "یا         → یا\n",
      "نشده_است   → شد#شو\n",
      "اتمام      → اتمام\n",
      "در تبادل مانده انتقالی کاربر پیغام خطای کد مل وارد شده را دریافت کرد#کن و بعد از آن خواست#خواه دید#بین مساله حل‌شده یا شد#شو اتمام\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "tokenizer = WordTokenizer()\n",
    "stemmer = Stemmer()\n",
    "text   = normalizer.normalize(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "lemmatizer = Lemmatizer()\n",
    "for tok in tokens:\n",
    "    # print(f\"{tok:<10} → {stemmer.stem(tok)}\")\n",
    "    print(f\"{tok:<10} → {lemmatizer.lemmatize(tok)}\")\n",
    "\n",
    "\n",
    "# 2. stem each token\n",
    "lemmatized_text = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
    "\n",
    "# 3. join into one string\n",
    "lemetized_with_hazm = \" \".join(lemmatized_text)\n",
    "print(lemetized_with_hazm)\n",
    "# 'کتاب'\n",
    "# tokens = word_tokenize(text)\n",
    "# list_stems = list(map(stemmer.stem, tokens))\n",
    "# list_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df44717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import POSTagger, word_tokenize\n",
    "\n",
    "# relative to your project root:\n",
    "tagger = POSTagger(model=\"resources/pos_tagger.model\")\n",
    "# print(tagger.tag(word_tokenize(\"ما بسیار کتاب می‌خوانیم\")))\n",
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی وارد شده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d1bedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('در', 'ADP'), ('تبادل', 'NOUN,EZ'), ('مانده\\u200cهای', 'NOUN,EZ'), ('انتقالی', 'ADJ,EZ'), ('کاربر', 'NOUN'), ('پیغام', 'NOUN'), ('خطای', 'NOUN,EZ'), ('کد', 'NOUN,EZ'), ('ملیتان', 'NOUN'), ('وارد', 'NOUN'), ('شده', 'VERB'), ('را', 'ADP'), ('دریافت', 'NOUN'), ('می\\u200cکند', 'VERB'), ('و', 'CCONJ'), ('بعد', 'ADP'), ('از', 'ADP'), ('آن', 'PRON'), ('می\\u200cخواهیم', 'VERB'), ('ببینیم', 'VERB'), ('مساله', 'NOUN,EZ'), ('حل\\u200cشده', 'ADJ'), ('یا', 'CCONJ'), ('نشده_است', 'VERB'), ('اتمام', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد ملی واردشده مرتبط با این عملیات نمی‌باشد دریافت می‌گردد در تمامی فعالیتهایی که منجر به ایجاد مانده انتقالی می‌شوند شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی از اطلاعات قبلی بازیابی نشده و کاربر ملزم به درج شناسه مشتری کدملی/ شناسه ملی در فرم پولشویی برای فعالیت بعدی می‌باشد جهت استعلام کدملی مربوط به مانده ایجادی می‌بایست از طریق سامانه بک آفیس پشتیبانی فنی بازیابی اطلاعات شناسه مشتری تسک انتقالی اقدام گردد\"\n",
    "\n",
    "print(tagger.tag(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2f6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'رفت#رو'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('می‌رود')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78cbdc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('در', 'ADP'),\n",
       "  ('تبادل', 'NOUN,EZ'),\n",
       "  ('مانده\\u200cهای', 'NOUN,EZ'),\n",
       "  ('انتقالی', 'ADJ,EZ'),\n",
       "  ('کاربر', 'NOUN'),\n",
       "  ('پیغام', 'NOUN'),\n",
       "  ('خطای', 'NOUN,EZ'),\n",
       "  ('کد', 'NOUN,EZ'),\n",
       "  ('ملیتان', 'NOUN'),\n",
       "  ('وارد', 'NOUN'),\n",
       "  ('شده', 'VERB'),\n",
       "  ('را', 'ADP'),\n",
       "  ('دریافت', 'NOUN'),\n",
       "  ('می\\u200cکند', 'VERB'),\n",
       "  ('و', 'CCONJ'),\n",
       "  ('بعد', 'ADP'),\n",
       "  ('از', 'ADP'),\n",
       "  ('آن', 'PRON'),\n",
       "  ('می\\u200cخواهیم', 'VERB'),\n",
       "  ('ببینیم', 'VERB'),\n",
       "  ('مساله', 'NOUN,EZ'),\n",
       "  ('حل\\u200cشده', 'ADJ'),\n",
       "  ('یا', 'CCONJ'),\n",
       "  ('نشده_است', 'VERB'),\n",
       "  ('اتمام', 'NOUN')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagger.tag_sents(sentences = [['من', 'به', 'مدرسه', 'ایران', 'رفته_بودم', '.']])\n",
    "tagger.tag_sents(sentences = [word_tokenize(text)])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a90295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['در',\n",
       " 'تبادل',\n",
       " 'مانده\\u200cهای',\n",
       " 'انتقالی',\n",
       " 'کاربر',\n",
       " 'پیغام',\n",
       " 'خطای',\n",
       " 'کد',\n",
       " 'ملیتان',\n",
       " 'وارد',\n",
       " 'شده',\n",
       " 'را',\n",
       " 'دریافت',\n",
       " 'می\\u200cکند',\n",
       " 'و',\n",
       " 'بعد',\n",
       " 'از',\n",
       " 'آن',\n",
       " 'می\\u200cخواهیم',\n",
       " 'ببینیم',\n",
       " 'مساله',\n",
       " 'حل\\u200cشده',\n",
       " 'یا',\n",
       " 'نشده_است',\n",
       " 'اتمام']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfdb0bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('در', 'ADP'),\n",
       " ('تبادل', 'NOUN,EZ'),\n",
       " ('مانده\\u200cهای', 'NOUN,EZ'),\n",
       " ('انتقالی', 'ADJ,EZ'),\n",
       " ('کاربر', 'NOUN'),\n",
       " ('پیغام', 'NOUN'),\n",
       " ('خطای', 'NOUN,EZ'),\n",
       " ('کد', 'NOUN,EZ'),\n",
       " ('ملیتان', 'NOUN'),\n",
       " ('وارد', 'NOUN'),\n",
       " ('شده', 'VERB'),\n",
       " ('را', 'ADP'),\n",
       " ('دریافت', 'NOUN'),\n",
       " ('می\\u200cکند', 'VERB'),\n",
       " ('و', 'CCONJ'),\n",
       " ('بعد', 'ADP'),\n",
       " ('از', 'ADP'),\n",
       " ('آن', 'PRON'),\n",
       " ('می\\u200cخواهیم', 'VERB'),\n",
       " ('ببینیم', 'VERB'),\n",
       " ('مساله', 'NOUN,EZ'),\n",
       " ('حل\\u200cشده', 'ADJ'),\n",
       " ('یا', 'CCONJ'),\n",
       " ('نشده_است', 'VERB'),\n",
       " ('اتمام', 'NOUN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "844ff39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'word': 'در',\n",
       "   'is_first': True,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'د',\n",
       "   'prefix-2': 'در',\n",
       "   'prefix-3': 'در',\n",
       "   'suffix-1': 'ر',\n",
       "   'suffix-2': 'در',\n",
       "   'suffix-3': 'در',\n",
       "   'prev_word': '',\n",
       "   'two_prev_word': '',\n",
       "   'next_word': 'تبادل',\n",
       "   'two_next_word': 'مانده\\u200cهای',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': '',\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': '',\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'تبادل',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ت',\n",
       "   'prefix-2': 'تب',\n",
       "   'prefix-3': 'تبا',\n",
       "   'suffix-1': 'ل',\n",
       "   'suffix-2': 'دل',\n",
       "   'suffix-3': 'ادل',\n",
       "   'prev_word': 'در',\n",
       "   'two_prev_word': 'اتمام',\n",
       "   'next_word': 'مانده\\u200cهای',\n",
       "   'two_next_word': 'انتقالی',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'مانده\\u200cهای',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'ما',\n",
       "   'prefix-3': 'مان',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'ای',\n",
       "   'suffix-3': 'های',\n",
       "   'prev_word': 'تبادل',\n",
       "   'two_prev_word': 'در',\n",
       "   'next_word': 'انتقالی',\n",
       "   'two_next_word': 'کاربر',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'انتقالی',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'ان',\n",
       "   'prefix-3': 'انت',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'لی',\n",
       "   'suffix-3': 'الی',\n",
       "   'prev_word': 'مانده\\u200cهای',\n",
       "   'two_prev_word': 'تبادل',\n",
       "   'next_word': 'کاربر',\n",
       "   'two_next_word': 'پیغام',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'کاربر',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ک',\n",
       "   'prefix-2': 'کا',\n",
       "   'prefix-3': 'کار',\n",
       "   'suffix-1': 'ر',\n",
       "   'suffix-2': 'بر',\n",
       "   'suffix-3': 'ربر',\n",
       "   'prev_word': 'انتقالی',\n",
       "   'two_prev_word': 'مانده\\u200cهای',\n",
       "   'next_word': 'پیغام',\n",
       "   'two_next_word': 'خطای',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'پیغام',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'پ',\n",
       "   'prefix-2': 'پی',\n",
       "   'prefix-3': 'پیغ',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'ام',\n",
       "   'suffix-3': 'غام',\n",
       "   'prev_word': 'کاربر',\n",
       "   'two_prev_word': 'انتقالی',\n",
       "   'next_word': 'خطای',\n",
       "   'two_next_word': 'کد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'خطای',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'خ',\n",
       "   'prefix-2': 'خط',\n",
       "   'prefix-3': 'خطا',\n",
       "   'suffix-1': 'ی',\n",
       "   'suffix-2': 'ای',\n",
       "   'suffix-3': 'طای',\n",
       "   'prev_word': 'پیغام',\n",
       "   'two_prev_word': 'کاربر',\n",
       "   'next_word': 'کد',\n",
       "   'two_next_word': 'ملیتان',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'کد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ک',\n",
       "   'prefix-2': 'کد',\n",
       "   'prefix-3': 'کد',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'کد',\n",
       "   'suffix-3': 'کد',\n",
       "   'prev_word': 'خطای',\n",
       "   'two_prev_word': 'پیغام',\n",
       "   'next_word': 'ملیتان',\n",
       "   'two_next_word': 'وارد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'ملیتان',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'مل',\n",
       "   'prefix-3': 'ملی',\n",
       "   'suffix-1': 'ن',\n",
       "   'suffix-2': 'ان',\n",
       "   'suffix-3': 'تان',\n",
       "   'prev_word': 'کد',\n",
       "   'two_prev_word': 'خطای',\n",
       "   'next_word': 'وارد',\n",
       "   'two_next_word': 'شده',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'وارد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'و',\n",
       "   'prefix-2': 'وا',\n",
       "   'prefix-3': 'وار',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'رد',\n",
       "   'suffix-3': 'ارد',\n",
       "   'prev_word': 'ملیتان',\n",
       "   'two_prev_word': 'کد',\n",
       "   'next_word': 'شده',\n",
       "   'two_next_word': 'را',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'شده',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ش',\n",
       "   'prefix-2': 'شد',\n",
       "   'prefix-3': 'شده',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'ده',\n",
       "   'suffix-3': 'شده',\n",
       "   'prev_word': 'وارد',\n",
       "   'two_prev_word': 'ملیتان',\n",
       "   'next_word': 'را',\n",
       "   'two_next_word': 'دریافت',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'را',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ر',\n",
       "   'prefix-2': 'را',\n",
       "   'prefix-3': 'را',\n",
       "   'suffix-1': 'ا',\n",
       "   'suffix-2': 'را',\n",
       "   'suffix-3': 'را',\n",
       "   'prev_word': 'شده',\n",
       "   'two_prev_word': 'وارد',\n",
       "   'next_word': 'دریافت',\n",
       "   'two_next_word': 'می\\u200cکند',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'دریافت',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'د',\n",
       "   'prefix-2': 'در',\n",
       "   'prefix-3': 'دری',\n",
       "   'suffix-1': 'ت',\n",
       "   'suffix-2': 'فت',\n",
       "   'suffix-3': 'افت',\n",
       "   'prev_word': 'را',\n",
       "   'two_prev_word': 'شده',\n",
       "   'next_word': 'می\\u200cکند',\n",
       "   'two_next_word': 'و',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'می\\u200cکند',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'می',\n",
       "   'prefix-3': 'می\\u200c',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'ند',\n",
       "   'suffix-3': 'کند',\n",
       "   'prev_word': 'دریافت',\n",
       "   'two_prev_word': 'را',\n",
       "   'next_word': 'و',\n",
       "   'two_next_word': 'بعد',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'و',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'و',\n",
       "   'prefix-2': 'و',\n",
       "   'prefix-3': 'و',\n",
       "   'suffix-1': 'و',\n",
       "   'suffix-2': 'و',\n",
       "   'suffix-3': 'و',\n",
       "   'prev_word': 'می\\u200cکند',\n",
       "   'two_prev_word': 'دریافت',\n",
       "   'next_word': 'بعد',\n",
       "   'two_next_word': 'از',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'بعد',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ب',\n",
       "   'prefix-2': 'بع',\n",
       "   'prefix-3': 'بعد',\n",
       "   'suffix-1': 'د',\n",
       "   'suffix-2': 'عد',\n",
       "   'suffix-3': 'بعد',\n",
       "   'prev_word': 'و',\n",
       "   'two_prev_word': 'می\\u200cکند',\n",
       "   'next_word': 'از',\n",
       "   'two_next_word': 'آن',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'از',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'از',\n",
       "   'prefix-3': 'از',\n",
       "   'suffix-1': 'ز',\n",
       "   'suffix-2': 'از',\n",
       "   'suffix-3': 'از',\n",
       "   'prev_word': 'بعد',\n",
       "   'two_prev_word': 'و',\n",
       "   'next_word': 'آن',\n",
       "   'two_next_word': 'می\\u200cخواهیم',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'آن',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'آ',\n",
       "   'prefix-2': 'آن',\n",
       "   'prefix-3': 'آن',\n",
       "   'suffix-1': 'ن',\n",
       "   'suffix-2': 'آن',\n",
       "   'suffix-3': 'آن',\n",
       "   'prev_word': 'از',\n",
       "   'two_prev_word': 'بعد',\n",
       "   'next_word': 'می\\u200cخواهیم',\n",
       "   'two_next_word': 'ببینیم',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'می\\u200cخواهیم',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'می',\n",
       "   'prefix-3': 'می\\u200c',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'یم',\n",
       "   'suffix-3': 'هیم',\n",
       "   'prev_word': 'آن',\n",
       "   'two_prev_word': 'از',\n",
       "   'next_word': 'ببینیم',\n",
       "   'two_next_word': 'مساله',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'ببینیم',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ب',\n",
       "   'prefix-2': 'بب',\n",
       "   'prefix-3': 'ببی',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'یم',\n",
       "   'suffix-3': 'نیم',\n",
       "   'prev_word': 'می\\u200cخواهیم',\n",
       "   'two_prev_word': 'آن',\n",
       "   'next_word': 'مساله',\n",
       "   'two_next_word': 'حل\\u200cشده',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'مساله',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'م',\n",
       "   'prefix-2': 'مس',\n",
       "   'prefix-3': 'مسا',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'له',\n",
       "   'suffix-3': 'اله',\n",
       "   'prev_word': 'ببینیم',\n",
       "   'two_prev_word': 'می\\u200cخواهیم',\n",
       "   'next_word': 'حل\\u200cشده',\n",
       "   'two_next_word': 'یا',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'حل\\u200cشده',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ح',\n",
       "   'prefix-2': 'حل',\n",
       "   'prefix-3': 'حل\\u200c',\n",
       "   'suffix-1': 'ه',\n",
       "   'suffix-2': 'ده',\n",
       "   'suffix-3': 'شده',\n",
       "   'prev_word': 'مساله',\n",
       "   'two_prev_word': 'ببینیم',\n",
       "   'next_word': 'یا',\n",
       "   'two_next_word': 'نشده_است',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'یا',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ی',\n",
       "   'prefix-2': 'یا',\n",
       "   'prefix-3': 'یا',\n",
       "   'suffix-1': 'ا',\n",
       "   'suffix-2': 'یا',\n",
       "   'suffix-3': 'یا',\n",
       "   'prev_word': 'حل\\u200cشده',\n",
       "   'two_prev_word': 'مساله',\n",
       "   'next_word': 'نشده_است',\n",
       "   'two_next_word': 'اتمام',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'نشده_است',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ن',\n",
       "   'prefix-2': 'نش',\n",
       "   'prefix-3': 'نشد',\n",
       "   'suffix-1': 'ت',\n",
       "   'suffix-2': 'ست',\n",
       "   'suffix-3': 'است',\n",
       "   'prev_word': 'یا',\n",
       "   'two_prev_word': 'حل\\u200cشده',\n",
       "   'next_word': 'اتمام',\n",
       "   'two_next_word': '',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': False,\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': False},\n",
       "  {'word': 'اتمام',\n",
       "   'is_first': False,\n",
       "   'is_last': True,\n",
       "   'prefix-1': 'ا',\n",
       "   'prefix-2': 'ات',\n",
       "   'prefix-3': 'اتم',\n",
       "   'suffix-1': 'م',\n",
       "   'suffix-2': 'ام',\n",
       "   'suffix-3': 'مام',\n",
       "   'prev_word': 'نشده_است',\n",
       "   'two_prev_word': 'یا',\n",
       "   'next_word': '',\n",
       "   'two_next_word': '',\n",
       "   'is_numeric': False,\n",
       "   'prev_is_numeric': False,\n",
       "   'next_is_numeric': '',\n",
       "   'is_punc': False,\n",
       "   'prev_is_punc': False,\n",
       "   'next_is_punc': ''}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_text = tagger.data_maker(tokens = [word_tokenize(text)])\n",
    "details_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e734f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "را\n",
      "شده\n"
     ]
    }
   ],
   "source": [
    "next_word = details_text[0][11-1].get(\"next_word\")\n",
    "own_word = details_text[0][11-1].get(\"word\")\n",
    "print(next_word)\n",
    "print(own_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfecf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_text = tagger.data_maker(tokens = [word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bcf8ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'در',\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'د',\n",
       "  'prefix-2': 'در',\n",
       "  'prefix-3': 'در',\n",
       "  'suffix-1': 'ر',\n",
       "  'suffix-2': 'در',\n",
       "  'suffix-3': 'در',\n",
       "  'prev_word': '',\n",
       "  'two_prev_word': '',\n",
       "  'next_word': 'تبادل',\n",
       "  'two_next_word': 'مانده\\u200cهای',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': '',\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': '',\n",
       "  'next_is_punc': False},\n",
       " {'word': 'تبادل',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ت',\n",
       "  'prefix-2': 'تب',\n",
       "  'prefix-3': 'تبا',\n",
       "  'suffix-1': 'ل',\n",
       "  'suffix-2': 'دل',\n",
       "  'suffix-3': 'ادل',\n",
       "  'prev_word': 'در',\n",
       "  'two_prev_word': 'اتمام',\n",
       "  'next_word': 'مانده\\u200cهای',\n",
       "  'two_next_word': 'انتقالی',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'مانده\\u200cهای',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'ما',\n",
       "  'prefix-3': 'مان',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'ای',\n",
       "  'suffix-3': 'های',\n",
       "  'prev_word': 'تبادل',\n",
       "  'two_prev_word': 'در',\n",
       "  'next_word': 'انتقالی',\n",
       "  'two_next_word': 'کاربر',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'انتقالی',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ا',\n",
       "  'prefix-2': 'ان',\n",
       "  'prefix-3': 'انت',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'لی',\n",
       "  'suffix-3': 'الی',\n",
       "  'prev_word': 'مانده\\u200cهای',\n",
       "  'two_prev_word': 'تبادل',\n",
       "  'next_word': 'کاربر',\n",
       "  'two_next_word': 'پیغام',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'کاربر',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ک',\n",
       "  'prefix-2': 'کا',\n",
       "  'prefix-3': 'کار',\n",
       "  'suffix-1': 'ر',\n",
       "  'suffix-2': 'بر',\n",
       "  'suffix-3': 'ربر',\n",
       "  'prev_word': 'انتقالی',\n",
       "  'two_prev_word': 'مانده\\u200cهای',\n",
       "  'next_word': 'پیغام',\n",
       "  'two_next_word': 'خطای',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'پیغام',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'پ',\n",
       "  'prefix-2': 'پی',\n",
       "  'prefix-3': 'پیغ',\n",
       "  'suffix-1': 'م',\n",
       "  'suffix-2': 'ام',\n",
       "  'suffix-3': 'غام',\n",
       "  'prev_word': 'کاربر',\n",
       "  'two_prev_word': 'انتقالی',\n",
       "  'next_word': 'خطای',\n",
       "  'two_next_word': 'کد',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'خطای',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'خ',\n",
       "  'prefix-2': 'خط',\n",
       "  'prefix-3': 'خطا',\n",
       "  'suffix-1': 'ی',\n",
       "  'suffix-2': 'ای',\n",
       "  'suffix-3': 'طای',\n",
       "  'prev_word': 'پیغام',\n",
       "  'two_prev_word': 'کاربر',\n",
       "  'next_word': 'کد',\n",
       "  'two_next_word': 'ملیتان',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'کد',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ک',\n",
       "  'prefix-2': 'کد',\n",
       "  'prefix-3': 'کد',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'کد',\n",
       "  'suffix-3': 'کد',\n",
       "  'prev_word': 'خطای',\n",
       "  'two_prev_word': 'پیغام',\n",
       "  'next_word': 'ملیتان',\n",
       "  'two_next_word': 'وارد',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'ملیتان',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'مل',\n",
       "  'prefix-3': 'ملی',\n",
       "  'suffix-1': 'ن',\n",
       "  'suffix-2': 'ان',\n",
       "  'suffix-3': 'تان',\n",
       "  'prev_word': 'کد',\n",
       "  'two_prev_word': 'خطای',\n",
       "  'next_word': 'وارد',\n",
       "  'two_next_word': 'شده',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'وارد',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'و',\n",
       "  'prefix-2': 'وا',\n",
       "  'prefix-3': 'وار',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'رد',\n",
       "  'suffix-3': 'ارد',\n",
       "  'prev_word': 'ملیتان',\n",
       "  'two_prev_word': 'کد',\n",
       "  'next_word': 'شده',\n",
       "  'two_next_word': 'را',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'شده',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ش',\n",
       "  'prefix-2': 'شد',\n",
       "  'prefix-3': 'شده',\n",
       "  'suffix-1': 'ه',\n",
       "  'suffix-2': 'ده',\n",
       "  'suffix-3': 'شده',\n",
       "  'prev_word': 'وارد',\n",
       "  'two_prev_word': 'ملیتان',\n",
       "  'next_word': 'را',\n",
       "  'two_next_word': 'دریافت',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'را',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ر',\n",
       "  'prefix-2': 'را',\n",
       "  'prefix-3': 'را',\n",
       "  'suffix-1': 'ا',\n",
       "  'suffix-2': 'را',\n",
       "  'suffix-3': 'را',\n",
       "  'prev_word': 'شده',\n",
       "  'two_prev_word': 'وارد',\n",
       "  'next_word': 'دریافت',\n",
       "  'two_next_word': 'می\\u200cکند',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'دریافت',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'د',\n",
       "  'prefix-2': 'در',\n",
       "  'prefix-3': 'دری',\n",
       "  'suffix-1': 'ت',\n",
       "  'suffix-2': 'فت',\n",
       "  'suffix-3': 'افت',\n",
       "  'prev_word': 'را',\n",
       "  'two_prev_word': 'شده',\n",
       "  'next_word': 'می\\u200cکند',\n",
       "  'two_next_word': 'و',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'می\\u200cکند',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'می',\n",
       "  'prefix-3': 'می\\u200c',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'ند',\n",
       "  'suffix-3': 'کند',\n",
       "  'prev_word': 'دریافت',\n",
       "  'two_prev_word': 'را',\n",
       "  'next_word': 'و',\n",
       "  'two_next_word': 'بعد',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'و',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'و',\n",
       "  'prefix-2': 'و',\n",
       "  'prefix-3': 'و',\n",
       "  'suffix-1': 'و',\n",
       "  'suffix-2': 'و',\n",
       "  'suffix-3': 'و',\n",
       "  'prev_word': 'می\\u200cکند',\n",
       "  'two_prev_word': 'دریافت',\n",
       "  'next_word': 'بعد',\n",
       "  'two_next_word': 'از',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'بعد',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ب',\n",
       "  'prefix-2': 'بع',\n",
       "  'prefix-3': 'بعد',\n",
       "  'suffix-1': 'د',\n",
       "  'suffix-2': 'عد',\n",
       "  'suffix-3': 'بعد',\n",
       "  'prev_word': 'و',\n",
       "  'two_prev_word': 'می\\u200cکند',\n",
       "  'next_word': 'از',\n",
       "  'two_next_word': 'آن',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'از',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ا',\n",
       "  'prefix-2': 'از',\n",
       "  'prefix-3': 'از',\n",
       "  'suffix-1': 'ز',\n",
       "  'suffix-2': 'از',\n",
       "  'suffix-3': 'از',\n",
       "  'prev_word': 'بعد',\n",
       "  'two_prev_word': 'و',\n",
       "  'next_word': 'آن',\n",
       "  'two_next_word': 'می\\u200cخواهیم',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'آن',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'آ',\n",
       "  'prefix-2': 'آن',\n",
       "  'prefix-3': 'آن',\n",
       "  'suffix-1': 'ن',\n",
       "  'suffix-2': 'آن',\n",
       "  'suffix-3': 'آن',\n",
       "  'prev_word': 'از',\n",
       "  'two_prev_word': 'بعد',\n",
       "  'next_word': 'می\\u200cخواهیم',\n",
       "  'two_next_word': 'ببینیم',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'می\\u200cخواهیم',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'می',\n",
       "  'prefix-3': 'می\\u200c',\n",
       "  'suffix-1': 'م',\n",
       "  'suffix-2': 'یم',\n",
       "  'suffix-3': 'هیم',\n",
       "  'prev_word': 'آن',\n",
       "  'two_prev_word': 'از',\n",
       "  'next_word': 'ببینیم',\n",
       "  'two_next_word': 'مساله',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'ببینیم',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ب',\n",
       "  'prefix-2': 'بب',\n",
       "  'prefix-3': 'ببی',\n",
       "  'suffix-1': 'م',\n",
       "  'suffix-2': 'یم',\n",
       "  'suffix-3': 'نیم',\n",
       "  'prev_word': 'می\\u200cخواهیم',\n",
       "  'two_prev_word': 'آن',\n",
       "  'next_word': 'مساله',\n",
       "  'two_next_word': 'حل\\u200cشده',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'مساله',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'م',\n",
       "  'prefix-2': 'مس',\n",
       "  'prefix-3': 'مسا',\n",
       "  'suffix-1': 'ه',\n",
       "  'suffix-2': 'له',\n",
       "  'suffix-3': 'اله',\n",
       "  'prev_word': 'ببینیم',\n",
       "  'two_prev_word': 'می\\u200cخواهیم',\n",
       "  'next_word': 'حل\\u200cشده',\n",
       "  'two_next_word': 'یا',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'حل\\u200cشده',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ح',\n",
       "  'prefix-2': 'حل',\n",
       "  'prefix-3': 'حل\\u200c',\n",
       "  'suffix-1': 'ه',\n",
       "  'suffix-2': 'ده',\n",
       "  'suffix-3': 'شده',\n",
       "  'prev_word': 'مساله',\n",
       "  'two_prev_word': 'ببینیم',\n",
       "  'next_word': 'یا',\n",
       "  'two_next_word': 'نشده_است',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'یا',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ی',\n",
       "  'prefix-2': 'یا',\n",
       "  'prefix-3': 'یا',\n",
       "  'suffix-1': 'ا',\n",
       "  'suffix-2': 'یا',\n",
       "  'suffix-3': 'یا',\n",
       "  'prev_word': 'حل\\u200cشده',\n",
       "  'two_prev_word': 'مساله',\n",
       "  'next_word': 'نشده_است',\n",
       "  'two_next_word': 'اتمام',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'نشده_است',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ن',\n",
       "  'prefix-2': 'نش',\n",
       "  'prefix-3': 'نشد',\n",
       "  'suffix-1': 'ت',\n",
       "  'suffix-2': 'ست',\n",
       "  'suffix-3': 'است',\n",
       "  'prev_word': 'یا',\n",
       "  'two_prev_word': 'حل\\u200cشده',\n",
       "  'next_word': 'اتمام',\n",
       "  'two_next_word': '',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': False,\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': False},\n",
       " {'word': 'اتمام',\n",
       "  'is_first': False,\n",
       "  'is_last': True,\n",
       "  'prefix-1': 'ا',\n",
       "  'prefix-2': 'ات',\n",
       "  'prefix-3': 'اتم',\n",
       "  'suffix-1': 'م',\n",
       "  'suffix-2': 'ام',\n",
       "  'suffix-3': 'مام',\n",
       "  'prev_word': 'نشده_است',\n",
       "  'two_prev_word': 'یا',\n",
       "  'next_word': '',\n",
       "  'two_next_word': '',\n",
       "  'is_numeric': False,\n",
       "  'prev_is_numeric': False,\n",
       "  'next_is_numeric': '',\n",
       "  'is_punc': False,\n",
       "  'prev_is_punc': False,\n",
       "  'next_is_punc': ''}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bdc8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"  در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d654f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = lemetized_with_hazm\n",
    "#text = \"در تبادل مانده انتقالی کاربر پیغام خطای کد مل وارد شده را دریافت کرد#کن و بعد از آن خواست#خواه دید#بین مساله حل‌شده یا شد#شو اتمام\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e999f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = lemmatized_sentence_stanza\n",
    "# text = \"در تبادل مانده های انتقالی کاربر پیغام خطا کد ملیت وارد شد را دریافت کرد و بعد از آن خواست دید مساله حل شد یا شد است اتمام\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3de8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Root extraction\n",
    "text = stemming_sentence_parsivar\n",
    "# text = \"در تبادل مانده انتقالی کاربر پیغام خطا کد ملیت وارد‌شده‌را دریافت کرد&کن و بعد از آن خواست&خواه دید&بین مساله حل‌شده‌یا‌نشده‌است اتمام\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70d693d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_word = details_text[0][0].get(\"prev_word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "262bb71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'در',\n",
       " 'is_first': True,\n",
       " 'is_last': False,\n",
       " 'prefix-1': 'د',\n",
       " 'prefix-2': 'در',\n",
       " 'prefix-3': 'در',\n",
       " 'suffix-1': 'ر',\n",
       " 'suffix-2': 'در',\n",
       " 'suffix-3': 'در',\n",
       " 'prev_word': '',\n",
       " 'two_prev_word': '',\n",
       " 'next_word': 'تبادل',\n",
       " 'two_next_word': 'مانده\\u200cهای',\n",
       " 'is_numeric': False,\n",
       " 'prev_is_numeric': '',\n",
       " 'next_is_numeric': False,\n",
       " 'is_punc': False,\n",
       " 'prev_is_punc': '',\n",
       " 'next_is_punc': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_text[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aef2ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import POSTagger, word_tokenize\n",
    "\n",
    "# relative to your project root:\n",
    "tagger = POSTagger(model=\"resources/pos_tagger.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6eb3231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[('در', 'ADP'), ('تبادل', 'NOUN,EZ'), ('مانده', 'NOUN,EZ'), ('های', 'NOUN,EZ'), ('انتقالی', 'ADJ'), ('کاربر', 'NOUN'), ('پیغام', 'NOUN'), ('خطا', 'NOUN'), ('کد', 'NOUN,EZ'), ('ملیت', 'NOUN'), ('وارد', 'NOUN'), ('را', 'ADP'), ('دریافت', 'VERB-COMPOND'), ('کرد', 'VERB-COMPOND')]\n",
      "23\n",
      "[('در', 'ADP'), ('تبادل', 'NOUN,EZ'), ('مانده', 'NOUN,EZ'), ('های', 'NOUN,EZ'), ('انتقالی', 'ADJ'), ('کاربر', 'NOUN'), ('پیغام', 'NOUN'), ('خطا', 'NOUN'), ('کد', 'NOUN,EZ'), ('ملیت', 'NOUN'), ('وارد', 'NOUN'), ('را', 'ADP'), ('دریافت', 'VERB-COMPOND'), ('کرد', 'VERB-COMPOND'), ('کرد', 'VERB'), ('و', 'CCONJ'), ('بعد', 'ADP'), ('از', 'ADP'), ('آن', 'PRON'), ('دید', 'VERB'), ('مساله', 'NOUN'), ('حل', 'VERB-COMPOND'), ('شد', 'VERB-COMPOND')]\n"
     ]
    }
   ],
   "source": [
    "all_tagger_results = tagger.tag(word_tokenize(text))\n",
    "details_text = tagger.data_maker(tokens = [word_tokenize(text)])\n",
    "dict_exception_verb = [\"شد\",\"کرد\",\"خواست\"]\n",
    "final_result =[]\n",
    "for i in range(1,len(all_tagger_results)):\n",
    "    \n",
    "    next_word = details_text[0][i-1].get(\"next_word\")\n",
    "    own_word = details_text[0][i-1].get(\"word\")\n",
    "    prev_word = details_text[0][i-1].get(\"prev_word\")\n",
    "    # print(next_word)\n",
    "    # print(own_word)\n",
    "    next_tag, next_token = tagger.tag([next_word])[0][1], tagger.tag([next_word])[0][0]\n",
    "    peresent_tag, present_token = tagger.tag([own_word])[0][1], tagger.tag([own_word])[0][0]\n",
    "    if prev_word == '':\n",
    "        previous_tag, previous_token = \"space\" , \"wightspace\"\n",
    "    else:\n",
    "        previous_tag, previous_token = tagger.tag([prev_word])[0][1], tagger.tag([prev_word])[0][0]\n",
    "    if next_tag == 'VERB' and next_token in dict_exception_verb and peresent_tag == 'NOUN':        \n",
    "        result_own = list (tagger.tag([own_word])[0])\n",
    "        result_own[1]= \"VERB-COMPOND\"\n",
    "        final_result.append( tuple (result_own))\n",
    "        result_next = list (tagger.tag([next_word])[0])\n",
    "        result_next[1]= \"VERB-COMPOND\"\n",
    "        final_result.append( tuple (result_next))\n",
    "        print(i)\n",
    "        print(final_result)\n",
    "\n",
    "    else:\n",
    "    # elif final_result[i][1] != \"VERB-COMPOND\":\n",
    "        if own_word in dict_exception_verb and previous_tag !='NOUN':\n",
    "            continue\n",
    "        final_result.append(all_tagger_results[i-1])\n",
    "        # final_result.append(tagger.tag([own_word])[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1adab37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from nltk import word_tokenize\n",
    "\n",
    "# # your exception verbs\n",
    "# EXC = {\"شد\", \"کرد\", \"خواست\"}\n",
    "\n",
    "# # tokenize & tag once\n",
    "# all_tagger_results = tagger.tag(word_tokenize(text))\n",
    "# # all_tagger_results = tagger.tag(tokens)\n",
    "# # e.g. [('در','ADP'),('تبادل','NOUN,EZ'),…('وارد','NOUN'),('شده','VERB'),…]\n",
    "\n",
    "# final_result = []\n",
    "# i = 0\n",
    "# n = len(all_tagger_results)\n",
    "\n",
    "# while i < n:\n",
    "#     word, tag = all_tagger_results[i]\n",
    "#     # peek at next token\n",
    "#     if i+1 < n:\n",
    "#         next_word, next_tag = all_tagger_results[i+1]\n",
    "#     else:\n",
    "#         next_word = next_tag = None\n",
    "\n",
    "#     # detect NOUN + exception‑VERB\n",
    "#     if tag.startswith(\"NOUN\") and next_tag == \"VERB\" and next_word in EXC:\n",
    "#         # relabel both as VERB‑COMPOND\n",
    "#         final_result.append((word, \"VERB-COMPOND\"))\n",
    "#         final_result.append((next_word, \"VERB-COMPOND\"))\n",
    "#         i += 2  # skip the next one since we've handled it\n",
    "#     else:\n",
    "#         # otherwise keep the original tag\n",
    "#         final_result.append((word, tag))\n",
    "#         i += 1\n",
    "\n",
    "# # if there’s a trailing token you never hit in the loop, it’s already in final_result\n",
    "# print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bca9b0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('در', 'ADP'),\n",
       " ('تبادل', 'NOUN,EZ'),\n",
       " ('مانده', 'NOUN,EZ'),\n",
       " ('های', 'NOUN,EZ'),\n",
       " ('انتقالی', 'ADJ'),\n",
       " ('کاربر', 'NOUN'),\n",
       " ('پیغام', 'NOUN'),\n",
       " ('خطا', 'NOUN'),\n",
       " ('کد', 'NOUN,EZ'),\n",
       " ('ملیت', 'NOUN'),\n",
       " ('وارد', 'NOUN'),\n",
       " ('را', 'ADP'),\n",
       " ('دریافت', 'VERB-COMPOND'),\n",
       " ('کرد', 'VERB-COMPOND'),\n",
       " ('کرد', 'VERB'),\n",
       " ('و', 'CCONJ'),\n",
       " ('بعد', 'ADP'),\n",
       " ('از', 'ADP'),\n",
       " ('آن', 'PRON'),\n",
       " ('دید', 'VERB'),\n",
       " ('مساله', 'NOUN'),\n",
       " ('حل', 'VERB-COMPOND'),\n",
       " ('شد', 'VERB-COMPOND'),\n",
       " ('شد', 'VERB'),\n",
       " ('یا', 'CCONJ'),\n",
       " ('است', 'VERB')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b014af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('در', 'ADP'),\n",
       " ('تبادل', 'NOUN,EZ'),\n",
       " ('مانده', 'NOUN,EZ'),\n",
       " ('های', 'NOUN,EZ'),\n",
       " ('انتقالی', 'ADJ'),\n",
       " ('کاربر', 'NOUN'),\n",
       " ('پیغام', 'NOUN'),\n",
       " ('خطا', 'NOUN'),\n",
       " ('کد', 'NOUN,EZ'),\n",
       " ('ملیت', 'NOUN'),\n",
       " ('وارد', 'NOUN'),\n",
       " ('شد', 'VERB'),\n",
       " ('را', 'ADP'),\n",
       " ('دریافت', 'NOUN'),\n",
       " ('کرد', 'VERB'),\n",
       " ('و', 'CCONJ'),\n",
       " ('بعد', 'ADP'),\n",
       " ('از', 'ADP'),\n",
       " ('آن', 'PRON'),\n",
       " ('خواست', 'VERB'),\n",
       " ('دید', 'VERB'),\n",
       " ('مساله', 'NOUN'),\n",
       " ('حل', 'NOUN'),\n",
       " ('شد', 'VERB'),\n",
       " ('یا', 'CCONJ'),\n",
       " ('شد', 'VERB'),\n",
       " ('است', 'VERB'),\n",
       " ('اتمام', 'NOUN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tagger_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb5a68",
   "metadata": {},
   "source": [
    "## using Stanza for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70003ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/word_embedding_Narenjestan/venv11-hazm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-02 08:04:27 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 433kB [00:00, 3.89MB/s]                    \n",
      "2025-08-02 08:04:27 INFO: Downloaded file to /home/mahdi/stanza_resources/resources.json\n",
      "2025-08-02 08:04:28 INFO: Loading these models for language: fa (Persian):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | perdt          |\n",
      "| mwt       | perdt          |\n",
      "| pos       | perdt_charlm   |\n",
      "| lemma     | perdt_nocharlm |\n",
      "==============================\n",
      "\n",
      "2025-08-02 08:04:28 INFO: Using device: cpu\n",
      "2025-08-02 08:04:28 INFO: Loading: tokenize\n",
      "2025-08-02 08:04:28 INFO: Loading: mwt\n",
      "2025-08-02 08:04:28 INFO: Loading: pos\n",
      "2025-08-02 08:04:29 INFO: Loading: lemma\n",
      "2025-08-02 08:04:29 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در تبادل مانده های انتقالی کاربر پیغام خطا کد ملیت وارد شد را دریافت کرد و بعد از آن خواست دید مساله حل شد یا شد است اتمام\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import re\n",
    "\n",
    "# 1. build your pipeline (if you haven’t already)\n",
    "nlp = stanza.Pipeline(\n",
    "    lang='fa',\n",
    "    processors='tokenize,mwt,pos,lemma',\n",
    "    use_gpu=False\n",
    ")\n",
    "\n",
    "# 2. run it\n",
    "text = \"در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# 3. collect lemmas\n",
    "lemmas = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "\n",
    "# 4. join into one string\n",
    "lemmatized_sentence_stanza = \" \".join(lemmas)\n",
    "\n",
    "# 5. (optional) clean up spaces before Persian punctuation\n",
    "lemmatized_sentence_stanza = re.sub(r\"\\s+([،؛؟!.\\,])\", r\"\\1\", lemmatized_sentence_stanza)\n",
    "\n",
    "print(lemmatized_sentence_stanza)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c9c62",
   "metadata": {},
   "source": [
    "# Using parsivar for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9d275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در         → در\n",
      "تبادل      → تبادل\n",
      "مانده‌های  → مانده\n",
      "انتقالی    → انتقالی\n",
      "کاربر      → کاربر\n",
      "پیغام      → پیغام\n",
      "خطای       → خطا\n",
      "کد         → کد\n",
      "ملیتان     → ملیت\n",
      "وارد‌شده‌را → وارد‌شده‌را\n",
      "دریافت     → دریافت\n",
      "می‌کند     → کرد&کن\n",
      "و          → و\n",
      "بعد        → بعد\n",
      "از         → از\n",
      "آن         → آن\n",
      "میخواهیم   → خواست&خواه\n",
      "ببینیم     → دید&بین\n",
      "مساله      → مساله\n",
      "حل‌شده‌یا‌نشده‌است → حل‌شده‌یا‌نشده‌است\n",
      "اتمام      → اتمام\n"
     ]
    }
   ],
   "source": [
    "from parsivar import Normalizer, Tokenizer, FindStems\n",
    "\n",
    "normalizer = Normalizer()\n",
    "tokenizer  = Tokenizer()\n",
    "stemmer    = FindStems()\n",
    "text = \" در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام \"\n",
    "# text   = \"کتاب‌های جذاب را من دیروز خریدم.\"\n",
    "text   = normalizer.normalize(text)\n",
    "tokens = tokenizer.tokenize_words(text)\n",
    "stemmed_text = []\n",
    "for tok in tokens:\n",
    "    print(f\"{tok:<10} → {stemmer.convert_to_stem(tok)}\")\n",
    "    stemmed_text.append(stemmer.convert_to_stem(tok))\n",
    "    # print(stemmed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a46929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "در تبادل مانده انتقالی کاربر پیغام خطا کد ملیت وارد‌شده‌را دریافت کرد&کن و بعد از آن خواست&خواه دید&بین مساله حل‌شده‌یا‌نشده‌است اتمام\n"
     ]
    }
   ],
   "source": [
    "from parsivar import Normalizer, Tokenizer, FindStems\n",
    "import re\n",
    "\n",
    "# 1. setup\n",
    "normalizer = Normalizer()\n",
    "tokenizer  = Tokenizer()\n",
    "stemmer    = FindStems()\n",
    "\n",
    "text = \"در تبادل مانده های انتقالی کاربر پیغام خطای کد ملیتان وارد شده را دریافت میکند و بعد از آن میخواهیم ببینیم مساله حل شده یا نشده است اتمام\"\n",
    "text = normalizer.normalize(text)\n",
    "tokens = tokenizer.tokenize_words(text)\n",
    "\n",
    "# 2. stem each token\n",
    "stemmed_text = [stemmer.convert_to_stem(tok) for tok in tokens]\n",
    "\n",
    "# 3. join into one string\n",
    "stemming_sentence_parsivar = \" \".join(stemmed_text)\n",
    "\n",
    "# 4. (optional) clean up space before punctuation\n",
    "stemming_sentence_parsivar = re.sub(r\"\\s+([،.;؟!])\", r\"\\1\", stemming_sentence_parsivar)\n",
    "\n",
    "print(stemming_sentence_parsivar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e242a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv11-hazm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
