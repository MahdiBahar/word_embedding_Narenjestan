{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef2e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['سطح سوم' , 'تعداد'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e929764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18875 entries, 0 to 18874\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   سوال    18875 non-null  object\n",
      " 1   جواب    18874 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 295.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "252247df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>سوال</th>\n",
       "      <th>جواب</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>در پردازش 717 (تبادل مانده انتقالی کاربر) پیغا...</td>\n",
       "      <td>در تمامی فعالیتهایی که منجر به ایجاد مانده انت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>جهت پیگیری مسائل مربوط به امور بازنشستگان بانک...</td>\n",
       "      <td>در صورتی که رمز ورود به سامانه فراموش شده است،...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بازخرید گواهی سپرده به صورت سیستمی انجام شده، ...</td>\n",
       "      <td>پردازش 911 (گزارش صورتحساب سی و پنج گردش آخر) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جهت فعال سازی اکسس کارت مشتری حقوقی از چه طریق...</td>\n",
       "      <td>ابتدا در پردازش 685 (فعال سازی کارت های مشتری ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>در پردازش 2937 (گزارش استعلام وضعیت درخواست دس...</td>\n",
       "      <td>ابتدا در پردازش 2934 (گزارش درخواست/تحویل دسته...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                سوال  \\\n",
       "0  در پردازش 717 (تبادل مانده انتقالی کاربر) پیغا...   \n",
       "1  جهت پیگیری مسائل مربوط به امور بازنشستگان بانک...   \n",
       "2  بازخرید گواهی سپرده به صورت سیستمی انجام شده، ...   \n",
       "3  جهت فعال سازی اکسس کارت مشتری حقوقی از چه طریق...   \n",
       "4  در پردازش 2937 (گزارش استعلام وضعیت درخواست دس...   \n",
       "\n",
       "                                                جواب  \n",
       "0  در تمامی فعالیتهایی که منجر به ایجاد مانده انت...  \n",
       "1  در صورتی که رمز ورود به سامانه فراموش شده است،...  \n",
       "2  پردازش 911 (گزارش صورتحساب سی و پنج گردش آخر) ...  \n",
       "3  ابتدا در پردازش 685 (فعال سازی کارت های مشتری ...  \n",
       "4  ابتدا در پردازش 2934 (گزارش درخواست/تحویل دسته...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def delete_duplicate_sentences_in_excel(input_path: str, output_path: str, drop_column: list) -> None:\n",
    "    \n",
    "    # Load the workbook into a DataFrame\n",
    "    df = pd.read_excel(input_path)\n",
    "    df.drop(drop_column, axis=1, inplace=True)\n",
    "    # Set to track sentences we've already kept\n",
    "    seen_sentences = set()\n",
    "\n",
    "    def dedup_text(text: str) -> str:\n",
    "    \n",
    "        if pd.isnull(text):\n",
    "            return text\n",
    "        # Split on punctuation followed by whitespace\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', str(text))\n",
    "        result_parts = []\n",
    "        for sentence in sentences:\n",
    "            key = sentence.strip()\n",
    "            if not key:\n",
    "                continue\n",
    "            if key not in seen_sentences:\n",
    "                seen_sentences.add(key)\n",
    "                result_parts.append(sentence)\n",
    "            else:\n",
    "                # duplicate — replace with blank\n",
    "                result_parts.append('')\n",
    "        # Rejoin, preserving order but skipping empty entries\n",
    "        return ' '.join([s for s in result_parts if s]).strip()\n",
    "\n",
    "    # Apply to every column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].apply(dedup_text)\n",
    "\n",
    "    # Save the deduplicated DataFrame\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"Deduplication complete. Clean file saved to: {output_path}\")\n",
    "    # return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Adjust these paths as needed\n",
    "    input_file = \"/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx\"\n",
    "    output_file = \"/home/mahdi/word_embedding_Narenjestan/dataset/deduplicated_sentences.xlsx\"\n",
    "    delete_duplicate_sentences_in_excel(input_file, output_file, ['سطح سوم' , 'تعداد'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1675dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2922623/2627332882.py:96: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  cleaned_df = df.applymap(filter_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Output saved to '/home/mahdi/word_embedding_Narenjestan/dataset/V_3_deduplicated_sentences.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # --- Prepare splitter & cleaner ---\n",
    "sentence_splitter = re.compile(r'(?<=[.!?])\\s+')\n",
    "\n",
    "\n",
    "# 1) Remove any leading \"در پردازش <digits>\"\n",
    "REMOVE_PROCESS    = re.compile(r'\\bپردازش\\s*\\d+\\s*')\n",
    "\n",
    "# 2) Inside your quoted error message, strip out\n",
    "#    \". خطای شماره <digits> [مرحله <digits>]\"\n",
    "REMOVE_ERROR_TAIL = re.compile(r'\\.\\s*خطای شماره\\s*\\d+(?:\\s*مرحله\\s*\\d+)?')\n",
    "\n",
    "# 3) Remove any digits (and intervening spaces) immediately before \"(\"\n",
    "REMOVE_LEADING_NUM_PAREN = re.compile(r'\\b\\d+\\s*\\(')\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # step 1\n",
    "    text = REMOVE_PROCESS.sub('', text)\n",
    "    # step 2\n",
    "    text = REMOVE_ERROR_TAIL.sub('', text)\n",
    "    # step 3\n",
    "    # Turn \"5912 (\" or \"5912   (\" into \"(\"\n",
    "    text = REMOVE_LEADING_NUM_PAREN.sub('(', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "def delete_sentences_by_repetition(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    drop_columns: Optional[List[str]] = None,\n",
    "    repetition_threshold: int = 50\n",
    ") -> None:\n",
    " \n",
    "    drop_columns = drop_columns or []\n",
    "\n",
    "    # --- 1) Load and drop ---\n",
    "    df = pd.read_excel(input_path, dtype=str).fillna('')\n",
    "    if drop_columns:\n",
    "        df = df.drop(columns=drop_columns, errors='ignore')\n",
    "\n",
    "\n",
    "    # --- 2) Count all (cleaned) sentences ---\n",
    "    sentence_counts = Counter()\n",
    "    for cell in df.values.flatten():\n",
    "\n",
    "        cleaned_cell = preprocess_text(str(cell))\n",
    "        for sent in sentence_splitter.split(cleaned_cell):\n",
    "            s = sent.strip()\n",
    "            if s:\n",
    "                sentence_counts[s] += 1\n",
    "\n",
    "    # --- 3) Build cleaned DataFrame ---\n",
    "    def filter_cell(cell: str) -> str:\n",
    "        kept = []\n",
    "        cleaned_cell = preprocess_text(str(cell))\n",
    "        for sent in sentence_splitter.split(cleaned_cell):\n",
    "            s = sent.strip()\n",
    "            # keep only if it exists and is under threshold\n",
    "            if s and sentence_counts[s] < repetition_threshold:\n",
    "                kept.append(s)\n",
    "        return ' '.join(kept)\n",
    "\n",
    "    cleaned_df = df.map(filter_cell)\n",
    "\n",
    "    # --- 4) Write results ---\n",
    "    counts_df = (\n",
    "        pd.DataFrame(sentence_counts.items(), columns=['sentence', 'count'])\n",
    "          .sort_values('count', ascending=False)\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        cleaned_df.to_excel(writer, sheet_name='Cleaned', index=False)\n",
    "        counts_df.to_excel(writer, sheet_name='Sentence Counts', index=False)\n",
    "\n",
    "    print(f\"Done! Output saved to '{output_path}'\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    delete_sentences_by_repetition(\n",
    "        input_path=\"/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx\",\n",
    "        output_path=\"/home/mahdi/word_embedding_Narenjestan/dataset/V_3_deduplicated_sentences.xlsx\",\n",
    "        drop_columns=['سطح سوم' , 'تعداد'],\n",
    "        repetition_threshold=20\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcff9b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(گزارش وضعیت استعلام سیاح از بانک مرکزی) پاسخ استعلام با شرح'در انتظار پاسخ' نمایش داده می شود.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"در پردازش 5919 (گزارش وضعیت استعلام سیاح از بانک مرکزی) پاسخ استعلام با شرح'در انتظار پاسخ' نمایش داده می شود.\"\n",
    "\n",
    "_REMOVE_PATTERN = re.compile(r'\\b(?:در پردازش|پردازش)\\s*\\d+\\b')\n",
    "\n",
    "_REMOVE_PATTERN.sub('', sent).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab05a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خطای شماره 403875\" دریافت می گردد.\n",
      "در (ابطال چک تخصیص یافته) پیغام خطای \"تمام سریال های وارد شده شرایط ابطال ندارند\" دریافت می گردد.\n",
      "در (ابطال ضمانتنامه) پیغام خطای \"اجرای عملیات ابطال ملزم به استفاده از پردازش 4489 می باشد\" دریافت می گردد.\n"
     ]
    }
   ],
   "source": [
    "# 1) Remove any leading \"در پردازش <digits>\"\n",
    "REMOVE_PROCESS    = re.compile(r'\\bدر پردازش\\s*\\d+\\s*')\n",
    "\n",
    "# 2) Inside your quoted error message, strip out\n",
    "#    \". خطای شماره <digits> [مرحله <digits>]\"\n",
    "REMOVE_ERROR_TAIL = re.compile(r'\\.\\s*خطای شماره\\s*\\d+(?:\\s*مرحله\\s*\\d+)?')\n",
    "\n",
    "# 3) Remove any digits (and intervening spaces) immediately before \"(\"\n",
    "REMOVE_LEADING_NUM_PAREN = re.compile(r'\\b\\d+\\s*\\(')\n",
    "\n",
    "def clean_sentence(text: str) -> str:\n",
    "    # step 1\n",
    "    text = REMOVE_PROCESS.sub('در ', text)\n",
    "    # step 2\n",
    "    text = REMOVE_ERROR_TAIL.sub('', text)\n",
    "    # step 3\n",
    "    # Turn \"5912 (\" or \"5912   (\" into \"(\"\n",
    "    text = REMOVE_LEADING_NUM_PAREN.sub('(', text)\n",
    "    return text.strip()\n",
    "\n",
    "orig = (\n",
    "    'خطای شماره 403875\" دریافت می گردد.'\n",
    ")\n",
    "\n",
    "print(clean_sentence(orig))\n",
    "\n",
    "sent = 'در (ابطال چک تخصیص یافته) پیغام خطای \"تمام سریال های وارد شده شرایط ابطال ندارند. خطای شماره 3504 مرحله 6\" دریافت می گردد.'\n",
    "print(clean_sentence(sent))\n",
    "\n",
    "\n",
    "sent2= 'در پردازش 4612 (ابطال ضمانتنامه) پیغام خطای \"اجرای عملیات ابطال ملزم به استفاده از پردازش 4489 می باشد. خطای شماره 3184744\" دریافت می گردد.'\n",
    "\n",
    "print(clean_sentence(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61397058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessing_main import preprocess\n",
    "\n",
    "input_path = \"/home/mahdi/word_embedding_Narenjestan/dataset/MEC-Narenjestan_cleaned-V0.2.xlsx\"\n",
    "df_edited = pd.read_excel(input_path, dtype=str).fillna('')\n",
    "\n",
    "# Clean every cell in the DataFrame\n",
    "df_clean = df_edited.map(\n",
    "        lambda cell: preprocess(\n",
    "        str(cell),\n",
    "        remove_punctuations=True,\n",
    "        replace_multiple_spaces=True\n",
    "    )\n",
    ")\n",
    "\n",
    "df_clean.to_excel(\"/home/mahdi/word_embedding_Narenjestan/dataset/MEC-Narenjestan_cleaned-V0.3.xlsx\",index=False)\n",
    "# Now you can continue with splitting, counting, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cc6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>سوال</th>\n",
       "      <th>جواب</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>در تبادل مانده انتقالی کاربر پیغام خطای کد ملی...</td>\n",
       "      <td>در تمامی فعالیتهایی که منجر به ایجاد مانده انت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>جهت پیگیری مسائل مربوط به امور بازنشستگان بانک...</td>\n",
       "      <td>در صورتی که رمز ورود به سامانه فراموش شده است ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بازخرید گواهی سپرده به صورت سیستمی انجام شده ا...</td>\n",
       "      <td>گزارش صورتحساب سی و پنج گردش آخر بررسی گردد در...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جهت فعال سازی اکسس کارت مشتری حقوقی از چه طریق...</td>\n",
       "      <td>ابتدا در فعال سازی کارت های مشتری حقوقی شماره ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>در گزارش استعلام وضعیت درخواست دسته چک پیغام خ...</td>\n",
       "      <td>ابتدا در گزارش درخواست تحویل دسته چک در کلیه ش...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                سوال  \\\n",
       "0  در تبادل مانده انتقالی کاربر پیغام خطای کد ملی...   \n",
       "1  جهت پیگیری مسائل مربوط به امور بازنشستگان بانک...   \n",
       "2  بازخرید گواهی سپرده به صورت سیستمی انجام شده ا...   \n",
       "3  جهت فعال سازی اکسس کارت مشتری حقوقی از چه طریق...   \n",
       "4  در گزارش استعلام وضعیت درخواست دسته چک پیغام خ...   \n",
       "\n",
       "                                                جواب  \n",
       "0  در تمامی فعالیتهایی که منجر به ایجاد مانده انت...  \n",
       "1  در صورتی که رمز ورود به سامانه فراموش شده است ...  \n",
       "2  گزارش صورتحساب سی و پنج گردش آخر بررسی گردد در...  \n",
       "3  ابتدا در فعال سازی کارت های مشتری حقوقی شماره ...  \n",
       "4  ابتدا در گزارش درخواست تحویل دسته چک در کلیه ش...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bf5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736888c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fd646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def dedup_ngrams_in_excel(input_path: str,\n",
    "                          output_path: str,\n",
    "                          max_occurrences: int = 10):\n",
    "    \n",
    "    # 1) Load\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    # 2) For each n-gram length\n",
    "    for n in [6, 5, 4, 3, 2]:\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        def dedup_cell(text):\n",
    "            if pd.isnull(text):\n",
    "                return text\n",
    "            # simple tokenization (words and punctuation split)\n",
    "            tokens = re.findall(r\"\\w+|[^\\w\\s]\", str(text), re.UNICODE)\n",
    "            result = list(tokens)  # copy for in-place blanking\n",
    "\n",
    "            # slide window\n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                gram = tuple(tokens[i:i+n])\n",
    "                counts[gram] += 1\n",
    "                if counts[gram] > max_occurrences:\n",
    "                    # blank out this over-quota n-gram\n",
    "                    for j in range(i, i+n):\n",
    "                        result[j] = \"\"\n",
    "\n",
    "            # reconstruct: drop blanks, join with spaces\n",
    "            cleaned = \" \".join(tok for tok in result if tok)\n",
    "            return cleaned\n",
    "\n",
    "        # apply to every cell\n",
    "        df = df.applymap(dedup_cell)\n",
    "\n",
    "    # 3) Save\n",
    "    df.to_excel(output_path, index=False)\n",
    "    print(f\"Done – cleaned file saved to '{output_path}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1489679/255363609.py:37: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(dedup_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done – cleaned file saved to '/home/mahdi/word_embedding_Narenjestan/dataset/dedup_ngrams_output.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_file = \"/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx\"              \n",
    "    out_file = \"/home/mahdi/word_embedding_Narenjestan/dataset/dedup_ngrams_output.xlsx\"        \n",
    "    dedup_ngrams_in_excel(in_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85996e6",
   "metadata": {},
   "source": [
    "## NGRAM with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_and_save_ngrams(input_xlsx: str,\n",
    "                            output_xlsx: str,\n",
    "                            min_n: int = 2,\n",
    "                            max_n: int = 6,\n",
    "                            drop_column: list = None,\n",
    "                            valid_count: int = 10):\n",
    "   \n",
    "    drop_column = drop_column or []\n",
    "    # 1) Load your data\n",
    "    df = pd.read_excel(input_xlsx, dtype=str).fillna('')\n",
    "    if drop_column:\n",
    "        df = df.drop(columns=drop_column, errors='ignore')\n",
    "\n",
    "    # 2) Concatenate all cells into one big lowercase string\n",
    "    full_text = df.astype(str).agg(' '.join, axis=1).str.cat(sep=' ').lower()\n",
    "\n",
    "    # 3) Tokenize on word characters\n",
    "    tokens = re.findall(r'\\w+', full_text)\n",
    "\n",
    "    # Helper: sliding-window generator\n",
    "    def ngrams(tokens, n):\n",
    "        return zip(*(tokens[i:] for i in range(n)))\n",
    "\n",
    "    # 4) Prepare an Excel writer\n",
    "    with pd.ExcelWriter(output_xlsx, engine='openpyxl') as writer:\n",
    "        for n in range(min_n, max_n + 1):\n",
    "            # Count all n-grams\n",
    "            counts = Counter(ngrams(tokens, n))\n",
    "            # Filter to only those >= valid_count\n",
    "            filtered = {gram: cnt for gram, cnt in counts.items() if cnt >= valid_count}\n",
    "            if not filtered:\n",
    "                # nothing to write for this n\n",
    "                continue\n",
    "\n",
    "            # Build a DataFrame from filtered counts\n",
    "            df_ng = (\n",
    "                pd.DataFrame(filtered.items(), columns=['ngram_tuple', 'count'])\n",
    "                  .assign(ngram=lambda d: d['ngram_tuple']\n",
    "                                         .apply(lambda tup: ' '.join(tup)))\n",
    "                  .loc[:, ['ngram', 'count']]\n",
    "                  .sort_values('count', ascending=False)\n",
    "                  .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            # Write to its own sheet\n",
    "            sheet_name = f\"{n}-grams\"\n",
    "            df_ng.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"All done! N-grams (count ≥ {valid_count}) saved to '{output_xlsx}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_and_save_ngrams(\n",
    "        input_xlsx=\"/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx\" ,        # ← your source file\n",
    "        output_xlsx=\"ngram_counts.xlsx\",    # ← where to write results\n",
    "        min_n=2,\n",
    "        max_n=10,\n",
    "        drop_column=['سطح سوم' , 'تعداد']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180d229",
   "metadata": {},
   "source": [
    "## NGRAM with filter (using NLTK for tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ede13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using nltk\n",
    "\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# from nltk import ngrams\n",
    "# from nltk.tokenize import wordpunct_tokenize\n",
    "# from collections import Counter\n",
    "\n",
    "# def extract_and_save_ngrams_nltk(input_xlsx: str,\n",
    "#                                  output_xlsx: str,\n",
    "#                                  min_n: int = 2,\n",
    "#                                  max_n: int = 6,\n",
    "#                                  drop_column: list = None,\n",
    "#                                  valid_count: int = 10):\n",
    "\n",
    "#     drop_column = drop_column or []\n",
    "\n",
    "#     # 1) Load data\n",
    "#     df = pd.read_excel(input_xlsx, dtype=str).fillna('')\n",
    "#     if drop_column:\n",
    "#         df = df.drop(columns=drop_column, errors='ignore')\n",
    "\n",
    "#     # 2) Combine all text into one lowercase blob\n",
    "#     full_text = df.astype(str).agg(' '.join, axis=1).str.cat(sep=' ').lower()\n",
    "\n",
    "#     # 3) Tokenize into words and punctuation (no external models)\n",
    "#     tokens = wordpunct_tokenize(full_text)\n",
    "\n",
    "#     # 4) Prepare Excel writer\n",
    "#     with pd.ExcelWriter(output_xlsx, engine='openpyxl') as writer:\n",
    "#         for n in range(min_n, max_n + 1):\n",
    "#             # Count all n-grams\n",
    "#             cnt = Counter(ngrams(tokens, n))\n",
    "#             # Keep only those with count >= valid_count\n",
    "#             filtered = {gram: c for gram, c in cnt.items() if c >= valid_count}\n",
    "#             if not filtered:\n",
    "#                 continue\n",
    "\n",
    "#             # Build DataFrame\n",
    "#             df_ng = (\n",
    "#                 pd.DataFrame(filtered.items(), columns=['ngram_tuple', 'count'])\n",
    "#                   .assign(\n",
    "#                       ngram=lambda d: d['ngram_tuple']\n",
    "#                                          .apply(lambda tup: ' '.join(tup))\n",
    "#                   )\n",
    "#                   .loc[:, ['ngram', 'count']]\n",
    "#                   .sort_values('count', ascending=False)\n",
    "#                   .reset_index(drop=True)\n",
    "#             )\n",
    "\n",
    "#             # Write to sheet named \"2-grams\", \"3-grams\", etc.\n",
    "#             sheet = f\"{n}-grams\"\n",
    "#             df_ng.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "#     print(f\"Done! N-grams (count ≥ {valid_count}) saved to '{output_xlsx}'.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     extract_and_save_ngrams_nltk(\n",
    "#         input_xlsx=\"/home/mahdi/word_embedding_Narenjestan/dataset/narenjestan_khowledgebase_editable.xlsx\" ,        # ← your source file\n",
    "#         output_xlsx=\"ngram_counts_nltk.xlsx\",    # ← where to write results\n",
    "#         min_n=2,\n",
    "#         max_n=10,\n",
    "#         drop_column=['سطح سوم' , 'تعداد']\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
